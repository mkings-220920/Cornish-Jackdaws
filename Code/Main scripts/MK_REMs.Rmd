---
title: "Darwin Board experiment REMs"
author: "MK"
date: "17 October 2020"
output:
  word_document: default
  html_document: default
---

Load required packages and functions

```{r}
setwd("C:\\Users\\Mike\\Documents\\DB_experiments\\Files for publication\\Data")
library(survival)
library(scales)
library(ggplot2)
source("C:\\Users\\Mike\\Documents\\DB_experiments\\Files for publication\\Scripts\\get_dyad_labels.R")   #A function for adding a dyad label column to a REM dataset
source("C:\\Users\\Mike\\Documents\\DB_experiments\\Files for publication\\Scripts\\repeat_degree.R") #A function for calculating the number of group members with which an individual has had multiple associations. Returns a time-varying covariate for use in REMs.
```


Individual-level hypotheses (Conditioned on Source). The input files for these analyses comprise permuted REM datasets produced by permutation of TARGET labels only (Perm 2 - Independent permutation of SOURCE and TARGET labels; see Extended Data Figure 6b) and subsequently processed in Eventnet 0.5.2

 - Model 1a: The relationship between individuals' quantity of past events with familiar same-class and different-class partners and future success.
 
 - Model 1b: The relationship between individuals' number of same-class and different-class partners, with which they have associated on multiple occasions, and future success. 
 
 Predicted values used for plotting (Figure 2) generated.

```{r}
#set working directory to folder containing relevant Eventnet output
#setwd("D:\\ptests_perm2_CS_061220_EVout\\ptests_perm2_CS_061220")

feed_files<-list.files(no..=TRUE)  #Get list of files within current directory
coop_indicator<-unlist(sapply(feed_files,function(x) grepl("COOP_EVENTS",x)))   #Find file names containing "COOP_EVENTS" (Eventnet cooperation observations output)
cond_files<-feed_files[coop_indicator]   #Filter list of all file names to just COOP_EVENTS files
cond_lista<-list()
cond_listb<-list()
pred_list1a<-list()
pred_list1b<-list()

pred_df1b<-as.data.frame(expand.grid(0:10,0:10))
colnames(pred_df1b)<-c("repeat_success_deg","repeat_fail_deg")

for(i in 1:length(cond_files))  #loop over files within subfolder
{
  print(i)
  coop.events<-read.csv(cond_files[i],header=T,row.names=NULL)  #read in current Eventnet output file
  coop.events$DAY<-floor(coop.events$TIME/(60*60*24))
  coop.events$TIME<-rescale(coop.events$TIME)
  coop.events$same_group<-apply(coop.events,1,function(x) if(as.numeric(x["source.is.groupA"])==as.numeric(x["target.is.groupA"])){1} else {0}) #Check the group assignments of each SOURCE and TARGET pair and create a binary indicator of whether the pair belonged to the same, or different, treatment groups
  coop.events$target.coop.count<-coop.events$target.num.success + coop.events$target.num.fails   #Calculate total number of interactions engaged in by the TARGET
  coop.events$target.degree<-coop.events$target.degree.success + coop.events$target.degree.failure   #Calculate overall (unweighted) degree
  coop.events$event.indicator<-apply(coop.events,1,function(x) if(x["TYPE"]=="NON-EVENT"){0} else {1})   #Make sure that events (1) and non-events (0) have separate labels
  
  coop.events$DYAD<-get_dyad_labels(coop.events)
  coop.events$target_repeat_success_count<-coop.events$target.num.success-coop.events$target.degree.success
  coop.events$target_repeat_fail_count<-coop.events$target.num.fails-coop.events$target.degree.failure
  coop.events<-repeat_degree(coop.events)
  
  success.locs.temp<-which(coop.events$TYPE=="COOP_SUCCESS")
  success.locs<-c(success.locs.temp,(success.locs.temp + 1))
  success.locs<-sort(success.locs)
  coop.events.success<-coop.events[success.locs,]
  my.surv.coop.success<-Surv(time=rep(1,dim(coop.events.success)[1]),event=coop.events.success$event.indicator)
  
  #Model 1a:
  tempw1a<-tryCatch(perm.model.coop<-coxph(my.surv.coop.success ~ 
                                target_repeat_success_count*target_repeat_fail_count
                              + strata(DAY) 
                             , data = coop.events.success),warning=function(w) return("W"))
  
  
  if(is.object(tempw1a)){
    cond_lista[[i]]<-as.data.frame(t(tempw1a$coefficients))
  } else {
    cond_lista[[i]]<-NULL
  }
  
  
   #Model 1b:
   tempw1b<-tryCatch(perm.model.coop<-coxph(my.surv.coop.success ~ 
                               repeat_success_deg*repeat_fail_deg 
                              + strata(DAY) 
                             , data = coop.events.success),warning=function(w) return("W"))
   
   
  if(is.object(tempw1b)){
    cond_listb[[i]]<-as.data.frame(t(tempw1b$coefficients))
    tempdf1b<-cbind(pred_df1b,as.data.frame(predict(tempw1b,newdata=pred_df1b,type="risk",reference="sample")))
    colnames(tempdf1b)[ncol(tempdf1b)]<-"PRED_VAL"               
    pred_list1b[[i]]<-tempdf1b
  } else {
    cond_listb[[i]]<-NULL
    pred_list1b[[i]]<-NULL
  }
  
}

cond_df_cs_a<-do.call(rbind,cond_lista)  #Combine coefficients from each permuted REM for a given model type to get a single dataframe of pREM coefficients (with nrow == nperm)
cond_df_cs_b<-do.call(rbind,cond_listb)


#Determine median coefficient value and 97.5% confidence interval from quantiles of pREM coefficient distribution. 97.5% CI used rather than 95% CI due to multiple testing (similar hypothesis tested using two models). As p-values are not being calculated, p-value thresholds are not adjusted to account for this (i.e. Bonferroni correction), rather this adjustment of confidence intervals is used to account for the multiple testing.

quant_list1a<-apply(cond_df_cs_a,2,function(x) data.frame(CI_LOW=quantile(x,probs=0.0125),MED=quantile(x,probs=0.5),CI_HIGH=quantile(x,probs=0.9875),MINIMUM=min(x),MAXIMUM=max(x),I.R.=exp(quantile(x,probs=0.5))))
quant_df1a<-do.call(rbind,quant_list1a)
write.csv(quant_df1a,"cond_cs_quantdf_1a.csv")

quant_list1b<-apply(cond_df_cs_b,2,function(x) data.frame(CI_LOW=quantile(x,probs=0.0125),MED=quantile(x,probs=0.5),CI_HIGH=quantile(x,probs=0.9875),MINIMUM=min(x),MAXIMUM=max(x),I.R.=exp(quantile(x,probs=0.5))))
quant_df1b<-do.call(rbind,quant_list1b)
write.csv(quant_df1b,"cond_cs_quantdf_1b.csv")

```



Dyad & Network-level hypotheses. The input files for these analyses comprise permuted REM datasets produced by permutation of all identity labels (Perm 1 - Non-independent permutation of SOURCE and TARGET labels; see Extended Data Figure 6a) and subsequently processed in Eventnet 0.5.2


 - Model 2: Changes in association rates over the course of the experiment (for different types of dyad: same/diff treatment group, affiliated/not affiliated, familiar/unfamiliar). 

 - Model 3: Differences in association rate attributable to properties of dyads (number of previous events, same/diff treatment group) for affiliates (a) and non-affiliates (b). 

 - Model 6: Changes in (local) network structure over the course of the experiment, as measured by triadic closure (closure of triads: interaction of two individuals that have previously both interacted with a common third individual).  Baseline (i.e. irrespective of experimental design) number of common associates per dyad and number of same-class associates per same-class dyad are modelled. 

```{r}
#set working directory to folder containing relevant Eventnet output
#setwd("C:\\Users\\Mike\\Documents\\DB_experiments\\perm1EVout_130822ptests_perm1_041220")

feed_files<-list.files(no..=TRUE)   #Get list of files within current directory
coop_indicator<-unlist(sapply(feed_files,function(x) grepl("COOP_EVENTS",x)))   #Find file names containing "COOP_EVENTS" (Eventnet cooperation observations output)
coop_files<-feed_files[coop_indicator]    #Filter list of all file names to just COOP_EVENTS files
cox_dyad_list_affil<-list()     
cox_dyad_list_nonaffil<-list() 
cox_trt_list<-list()
cox_tri_list<-list() 
pred_list3a<-list()
pred_list3b<-list()
pred_list4<-list()
perc_store<-c()
perc_store_list<-list()


for(i in 1:length(coop_files))  #loop over all cooperation files in directory
{
  print(i)
  coop.events<-read.csv(coop_files[i],header=T,row.names=NULL)  #read in current Eventnet output file
  coop.events$DAY<-floor(coop.events$TIME/(60*60*24))
  coop.events$same_group<-apply(coop.events,1,function(x) if(as.numeric(x["source.is.groupA"])==as.numeric(x["target.is.groupA"])){1} else {0}) #Check the group assignments of each SOURCE and TARGET pair and create a binary indicator of whether the pair belonged to the same, or different, treatment groups.
  #coop.events$lock.bool<-as.numeric(unlist(apply(coop.events,1,function(x) context_clip[which(as.numeric(context_clip[,"TIME"]) %in% as.numeric(x["TIME"]))[1],"lock_bool"])))   #add task state info (lockout == 1, non-lockout == 0) for each event
  coop.events$TIME_rescaled<-rescale(coop.events$TIME)  #rescale to make parameter more interpretable
  coop.events$dyad.coop.count<-coop.events$dyad.success.count + coop.events$dyad.fail.count    #Get a single variable containing info on number of events engaged in by a dyad.
  coop.events$dyad.coop.cat<-sapply(as.numeric(coop.events$dyad.coop.count),function(x) if(x<1){"ARE_UNFAMILIAR"} else if(x>0 && x<6){"FAMILIAR_1TO5"} else {"FAMILIAR_6PLUS"})     #Split count of dyadic cooperation events into three categories (ARE_UNFAMILIAR = dyad has not had a previous event; FAMILIAR_1TO5 = dyad has had between one and five previous events; FAMILIAR_6PLUS = dyad has had six or more previous events)
  coop.events$is.affiliate<-sapply(coop.events$is.affiliate,function(x) if(x>0){1} else{0})    #ensure that affiliation indicator is 0/1 (affiliated==1)
  coop.events$dyad.has.previous<-coop.events$dyad.has.previous.fail + coop.events$dyad.has.previous.success  #Single variable indicating whether a dyad has had at least one previous interaction
  coop.events$dyad.has.previous<-apply(coop.events,1,function(x) if(as.numeric(x["dyad.has.previous"])>0){1} else {0})  #ensure that dyad.has.previous indicator is 0/1 (has had a previous event == 1)
  coop.events$event.indicator<-apply(coop.events,1,function(x) if(x["TYPE"]=="NON-EVENT"){0} else {1})   #Make sure that events (1) and non-events (0) have separate labels
  my.surv.coop<-Surv(time = rep(1,dim(coop.events)[1]), event = coop.events$event.indicator)
  
  #Model 2: Change in likelihood of observing same/different class dyads over time
  tempw2<-tryCatch(perm.net.coop<-coxph(my.surv.coop ~ 
                                            network.num.coop*same_group 
                                            - network.num.coop
                                            + strata(DAY) 
                                            , data = coop.events),warning=function(w) return("W"))
    
    if(is.object(tempw2)){         #If the model has been fitted successfully (i.e. without warnings)
      cox_trt_list[[i]]<-as.data.frame(t(tempw2$coefficients))           #Store model coefficients as a dataframe in the current list element
    } else {
      cox_trt_list[[i]]<-NULL
    }
    
  
  
  
  #Model 3a: Associations of affiliate dyads
  affil.locs.temp<-which(coop.events$is.affiliate>0 & coop.events$TYPE!="NON-EVENT")
  affil.locs<-c(affil.locs.temp,(affil.locs.temp + 1))
  affil.locs<-sort(affil.locs)
  coop.events.affil<-coop.events[affil.locs,]
  
  my.surv.coop.affil<-Surv(time = rep(1,dim(coop.events.affil)[1]), event = coop.events.affil$event.indicator)
  
  tempw3a<-tryCatch(perm.dyad.coop<-coxph(my.surv.coop.affil ~ 
                                           same_group*dyad.coop.cat
                                             + strata(DAY) 
                                             , data = coop.events.affil),warning=function(w) return("W"))
    
    if(is.object(tempw3a)){        #If the model has been fitted successfully (i.e. without warnings)
      cox_dyad_list_affil[[i]]<-as.data.frame(t(tempw3a$coefficients))     #Store model coefficients as a dataframe in the current list element
      newdf3a<-data.frame(same_group=rep(c(0,1),3),dyad.coop.cat=c("ARE_UNFAMILIAR","ARE_UNFAMILIAR","FAMILIAR_1TO5","FAMILIAR_1TO5","FAMILIAR_6PLUS","FAMILIAR_6PLUS"))      #create a new dataset for the purpose of getting predicted values from the REM
      tempdf3a<-cbind(newdf3a,as.data.frame(predict(tempw3a,newdata=newdf3a,type="risk",reference="sample")))
      colnames(tempdf3a)[ncol(tempdf3a)]<-"PRED_VAL"
      pred_list3a[[i]]<-tempdf3a  #Get predicted values for each of the scenarios contained in the 'newdata' dataframe from the REM. Results returned as relative risks (i.e. exp(raw coef)) and a single sample-wide baseline hazard is used (reference=sample). see ?predict.coxph for more details.
    } else {
      cox_dyad_list_affil[[i]]<-NULL
      pred_list3a[[i]]<-NULL
    }
    
    
    
    #Model 3b: Associations of non-affiliate dyads
    nonaffil.locs.temp<-which(coop.events$is.affiliate==0 & coop.events$TYPE!="NON-EVENT")
    nonaffil.locs<-c(nonaffil.locs.temp,(nonaffil.locs.temp + 1))
    nonaffil.locs<-sort(nonaffil.locs)
    coop.events.nonaffil<-coop.events[nonaffil.locs,]
    my.surv.coop.nonaffil<-Surv(time = rep(1,dim(coop.events.nonaffil)[1]), event = coop.events.nonaffil$event.indicator)
    
    
    tempw3b<-tryCatch(perm.dyad.coop<-coxph(my.surv.coop.nonaffil ~ 
                                           same_group*dyad.coop.cat
                                             + strata(DAY) 
                                             , data = coop.events.nonaffil),warning=function(w) return("W"))
    
    
    if(is.object(tempw3b)){        #If the model has been fitted successfully (i.e. without warnings)
      cox_dyad_list_nonaffil[[i]]<-as.data.frame(t(tempw3b$coefficients))     #Store model coefficients as a dataframe in the current list element
      newdf3b<-data.frame(same_group=rep(c(0,1),3),dyad.coop.cat=c("ARE_UNFAMILIAR","ARE_UNFAMILIAR","FAMILIAR_1TO5","FAMILIAR_1TO5","FAMILIAR_6PLUS","FAMILIAR_6PLUS"))      #create a new dataset for the purpose of getting predicted values from the REM
      tempdf3b<-cbind(newdf3b,as.data.frame(predict(tempw3b,newdata=newdf3b,type="risk",reference="sample")))
      colnames(tempdf3b)[ncol(tempdf3b)]<-"PRED_VAL"
      pred_list3b[[i]]<-tempdf3b  #Get predicted values for each of the scenarios contained in the 'newdata' dataframe from the REM. Results returned as relative risks (i.e. exp(raw coef)) and a single sample-wide baseline hazard is used (reference=sample). see ?predict.coxph for more details.
    } else {
      cox_dyad_list_nonaffil[[i]]<-NULL
      pred_list3b[[i]]<-NULL
    }
    
    
    
    #Model 6: Change in common associates over time
    tempw6<-tryCatch(unperm.triad.coop<-coxph(my.surv.coop ~ network.num.coop*(triadic.closure.coop + success.closure) - network.num.coop
                                                + strata(DAY) 
                                                , data = coop.events),warning=function(w) return("W"))
    
    
    if(is.object(tempw6)){                 #If the model has been fitted successfully (i.e. without warnings)
      cox_tri_list[[i]]<-as.data.frame(t(tempw6$coefficients))       #Store model coefficients as a dataframe in the current list element
      time_temp<-as.numeric(coop.events[coop.events$TYPE!="NON-EVENT","TIME"])
      events_temp<-floor(as.numeric(unlist(lapply(split(coop.events,coop.events$DAY),function(x) median(x$network.num.coop)))))
      tt2<-unique(time_temp[which(coop.events[coop.events$TYPE!="NON-EVENT","network.num.coop"] %in% events_temp)])
      day_temp<-floor(tt2/(24*60*60))
      tri_combinations<-expand.grid(day_temp,3,c(0,3))
      newdf6<-data.frame(network.num.coop=rep(events_temp,nrow(tri_combinations)/length(day_temp)),triadic.closure.coop=tri_combinations[,2],success.closure=tri_combinations[,3],DAY=tri_combinations[,1])
      tempdf6<-cbind(newdf6,as.data.frame(predict(tempw6,newdata=newdf6,type="risk",reference="strata")))
      colnames(tempdf6)[ncol(tempdf6)]<-"PRED_VAL"
      pred_list6[[i]]<-tempdf6
    } else {
      cox_tri_list[[i]]<-NULL
      pred_list6[[i]]<-NULL
    }
  
    
  #Calculate success/fail differential from the data from each permuted dataset for use in Figure 3 (see red line and shading).  
  temp_nonevents<-coop.events[coop.events$TYPE=="NON-EVENT",]  #'non-events' = permuted data (i.e., expected rather than observed) 
  perc_store<-c(perc_store,(length(which(temp_nonevents$same_group==1))/nrow(temp_nonevents)))    #proportion of 'non-events' that are successes
  diff.counter<-apply(temp_nonevents,1,function(x) if(x["same_group"]==1){1} else if(x["same_group"]==0){-1})    #label successes as positive, failures as negative 
  daytemp<-floor(temp_nonevents$TIME/(3600*24))
  temp_daydf<-data.frame(EVENT=1:length(diff.counter),sf_diff=diff.counter,Day=daytemp)
  temp_daydf$Day<-temp_daydf$Day-(min(temp_daydf$Day)-1)    #Get Days since day of first interaction
  tempfac<-as.factor(temp_daydf$Day)
  levels(tempfac)<-as.character(1:length(unique(temp_daydf$Day)))
  temp_daydf$Day<-as.numeric(as.character(tempfac))
  day_list<-lapply(split(temp_daydf,temp_daydf$Day),function(x) data.frame(Day=unique(x[,"Day"]),sf_diff=sum(x[,"sf_diff"]),nevents=nrow(x)))  #Get per-day success/fail differential for the ith permuted dataset
  daydf<-do.call(rbind,day_list)
  daydf$csum<-cumsum(daydf$sf_diff)  #Get cumulative sum of per-day success/fail differential for the ith permuted dataset
  perc_store_list[[i]]<-daydf
}

#coop_only<-coop.events[coop.events$TYPE!="NON-EVENT",]
#save(coop_only,file="coop_only.RData")

cox_dyad_df_affil<-do.call(rbind,cox_dyad_list_affil)    #Combine coefficients from each permuted REM for a given model type to get a single dataframe of pREM coefficients (with nrow == nperm)
cox_dyad_df_nonaffil<-do.call(rbind,cox_dyad_list_nonaffil)    #Combine coefficients from each permuted REM for a given model type to get a single dataframe of pREM coefficients (with nrow == nperm)
cox_trt_df<-do.call(rbind,cox_trt_list)
cox_tri_df<-do.call(rbind,cox_tri_list)



#Determine median coefficient values and 95% confidence intervals from quantiles of pREM coefficient distributions:

quant_list2<-apply(cox_trt_df,2,function(x) data.frame(CI_LOW=quantile(x,probs=0.025),MED=quantile(x,probs=0.5),CI_HIGH=quantile(x,probs=0.975),MINIMUM=min(x),MAXIMUM=max(x),I.R.=exp(quantile(x,probs=0.5))))
quant_df2<-do.call(rbind,quant_list2)
write.csv(quant_df2,"quant_df2.csv")

quant_list3a<-apply(cox_dyad_df_affil,2,function(x) data.frame(CI_LOW=quantile(x,probs=0.025),MED=quantile(x,probs=0.5),CI_HIGH=quantile(x,probs=0.975),MINIMUM=min(x),MAXIMUM=max(x),I.R.=exp(quantile(x,probs=0.5))))
quant_df3a<-do.call(rbind,quant_list3a)
#write.csv(quant_df3a,"dyad_quantdf3a.csv")

quant_list3b<-apply(cox_dyad_df_nonaffil,2,function(x) data.frame(CI_LOW=quantile(x,probs=0.025),MED=quantile(x,probs=0.5),CI_HIGH=quantile(x,probs=0.975),MINIMUM=min(x),MAXIMUM=max(x),I.R.=exp(quantile(x,probs=0.5))))
quant_df3b<-do.call(rbind,quant_list3b)
#write.csv(quant_df3b,"dyad_quantdf3b.csv")

quant_list6<-apply(cox_tri_df,2,function(x) data.frame(CI_LOW=quantile(x,probs=0.025),MED=quantile(x,probs=0.5),CI_HIGH=quantile(x,probs=0.975),MINIMUM=min(x),MAXIMUM=max(x),I.R.=exp(quantile(x,probs=0.5))))
quant_df6<-do.call(rbind,quant_list6)
#write.csv(quant_df4,"quant_df4.csv")

```




Tests for change in coordination of dyads (duration of events and arrival latencies). The input files for these analyses comprise permuted REM datasets produced by permutation of edge weights or arrival latencies only (Perm 4 - shuffle edge weights only (i.e. without altering the underlying network structure); see Extended Data Figure 6d) and subsequently processed in Eventnet 0.5.2 


- Model 4: Change in arrival latency (latency between arrival of SOURCE and TARGET preceding an association event) attributable to experimental treatment (same/different treatment class)


```{r}
setwd("D:\\ptests_perm4_101220_EVout_220822run\\ptests_perm4_101220_PREDUR")

feed_files<-list.files(no..=TRUE) #Get list of files within current directory
coop_indicator<-unlist(sapply(feed_files,function(x) grepl("COOP_EVENTS",x)))
coop_files<-feed_files[coop_indicator]
coef_list_4<-list()
pred_list_4<-list()

for(i in 1:length(coop_files))  #loop over files within subfolder
{
  print(i)
  coop.events.cdn<-read.csv(coop_files[i],header=T,row.names=NULL)
  coop.events.cdn$DAY<-floor(coop.events.cdn$TIME/(60*60*24))
  temp_groupdf<-covars[covars$TYPE=="IS_GROUP_A",]
  coop.events.cdn$same_group<-apply(coop.events.cdn,1,function(x) if(temp_groupdf[match(x["SOURCE"],temp_groupdf$SOURCE),"WEIGHT"]==temp_groupdf[match(x["TARGET"],temp_groupdf$TARGET),"WEIGHT"]) {1} else {0})  #Check the group assignments of each SOURCE and TARGET pair and create a binary indicator of whether the pair belonged to the same, or different, treatment groups.
  
  #coop.events.cdn$same_group<-apply(coop.events.cdn,1,function(x)  if(as.numeric(x["source.is.groupA"])==as.numeric(x["target.is.groupA"])){1} else {0}) #Check the group assignments of each SOURCE and TARGET pair and create a binary indicator of whether the pair belonged to the same, or different, treatment groups.
  cdn.list<-lapply(split(coop.events.cdn,coop.events.cdn$EVENT_INTERVAL),function(x) if(length(unique(x$EVENT))==2 & length(unique(x$TYPE))==2 & !sum(is.na(x$WEIGHT))){x} else {NULL})
  cdn.final<-do.call(rbind,cdn.list)
  cdn.final$event.indicator<-apply(cdn.final,1,function(x) if(x["TYPE"]=="NON-EVENT"){0} else {1})   #Make sure that events (1) and non-events (0) have separate labels
  my.surv.cdn<-Surv(time = rep(1,dim(cdn.final)[1]), event = cdn.final$event.indicator)  #Create a survival object to serve as the response term in coxph
  
  tempw4<-tryCatch(perm.coord<-coxph(my.surv.cdn ~ 
                                             WEIGHT*same_group 
                                              + strata(DAY) 
                                             , data = cdn.final),warning=function(w) return("W"))
  
  if(is.object(tempw4)){
    coef_list_4[[i]]<-as.data.frame(t(tempw4$coefficients))
    newdf4<-data.frame(WEIGHT=rep(1:60,2),same_group=rep(c(0,1),each=60))
    tempdf4<-cbind(newdf4,as.data.frame(predict(tempw4,newdata=newdf4,type="risk",reference="sample")))
    colnames(tempdf4)[ncol(tempdf4)]<-"PRED_VAL"
    pred_list_4[[i]]<-tempdf4
  } else {
    coef_list_4[[i]]<-NULL
    pred_list_4[[i]]<-NULL
  }
}

coop_only_predur<-coop.events.cdn[coop.events.cdn$TYPE!="NON-EVENT",]

coef_df_4<-do.call(rbind,coef_list_4)

quant_list4<-apply(coef_df_4[,c("WEIGHT","same_group","WEIGHT:same_group")],2,function(x) data.frame(CI_LOW=quantile(x,probs=0.025),MED=quantile(x,probs=0.5),CI_HIGH=quantile(x,probs=0.975),MINIMUM=min(x),MAXIMUM=max(x),I.R.=exp(quantile(x,probs=0.5))))
quant_df4<-do.call(rbind,quant_list4)
write.csv(quant_df4,"quant_df4.csv")
```


 - Model 5: Change in event duration of dyads attributable to experimental treatment (same/different treatment class)

```{r}
setwd("E:\\Eventnet output backup 280322\\ptests_perm4_091220_WEIGHT_EVout\\ptests_perm4_091220_WEIGHT")

feed_files<-list.files(no..=TRUE) #Get list of files within current directory
coop_indicator<-unlist(sapply(feed_files,function(x) grepl("COOP_EVENTS",x)))
coop_files<-feed_files[coop_indicator]
coef_list_5<-list()
pred_list_5<-list()

for(i in 1510:length(coop_files))  #loop over files within subfolder
{
  print(i)
  coop.events.cdn<-read.csv(coop_files[i],header=T,row.names=NULL)
  coop.events.cdn$DAY<-floor(coop.events.cdn$TIME/(60*60*24))
  coop.events.cdn$same_group<-apply(coop.events.cdn,1,function(x)  if(as.numeric(x["source.is.groupA"])==as.numeric(x["target.is.groupA"])){1} else {0}) #Check the group assignments of each SOURCE and TARGET pair and create a binary indicator of whether the pair belonged to the same, or different, treatment groups.
  cdn.list<-lapply(split(coop.events.cdn,coop.events.cdn$EVENT_INTERVAL),function(x) if(length(unique(x$EVENT))==2 & length(unique(x$TYPE))==2 & !sum(is.na(x$WEIGHT))){x} else {NULL})
  cdn.final<-do.call(rbind,cdn.list)
  cdn.final$event.indicator<-apply(cdn.final,1,function(x) if(x["TYPE"]=="NON-EVENT"){0} else {1})   #Make sure that events (1) and non-events (0) have separate labels
  my.surv.cdn<-Surv(time = rep(1,dim(cdn.final)[1]), event = cdn.final$event.indicator)  #Create a survival object to serve as the response term in coxph
  
  tempw5<-tryCatch(perm.coord<-coxph(my.surv.cdn ~ 
                                             WEIGHT*same_group
                                              + strata(DAY) 
                                             , data = cdn.final),warning=function(w) return("W"))
  
  if(is.object(tempw5)){
    coef_list_5[[i]]<-as.data.frame(t(tempw5$coefficients))
    newdf5<-data.frame(WEIGHT=rep(1:60,2),same_group=rep(c(0,1),each=60))
    tempdf5<-cbind(newdf5,as.data.frame(predict(tempw5,newdata=newdf5,type="risk",reference="sample")))
    colnames(tempdf5)[ncol(tempdf5)]<-"PRED_VAL"
    pred_list_5[[i]]<-tempdf5
  } else {
    coef_list_5[[i]]<-NULL
    pred_list_5[[i]]<-NULL
  }
}

coef_df_5<-do.call(rbind,coef_list_5)

quant_list5<-apply(coef_df_5[,c("WEIGHT","same_group","WEIGHT:same_group")],2,function(x) data.frame(CI_LOW=quantile(x,probs=0.025),MED=quantile(x,probs=0.5),CI_HIGH=quantile(x,probs=0.975),MINIMUM=min(x),MAXIMUM=max(x),I.R.=exp(quantile(x,probs=0.5))))
quant_df5<-do.call(rbind,quant_list5)
write.csv(quant_df5,"quant_df5.csv")
```


Note, Model 6 (change in common associates over time) as presented in the paper is located in the third code chunk (above, see line 230) as it utilizes the same permuted datasets as models 2 and 3. 






Plotting:

- Calculation of sample-wide baseline per-dyad and per-individual event rate (per hour) estimates for use in figures. 

```{r}
load("~/DB_experiments/Files for publication/Data/coop_only020722.RData")

coop_only$DYAD<-get_dyad_labels(coop_only)

#Calculate an estimate of baseline rate of association (across whole sample) for all dyad types
coop_only$Hour<-floor(coop_only$TIME/3600)
per_hour<-lapply(split(coop_only,coop_only$Hour),function(x) data.frame(Hour=unique(x[,"Hour"]),num_indivs=length(unique(c(x[,"SOURCE"],x[,"TARGET"]))),num_events=nrow(x),num_dyads=length(unique(x[,"DYAD"]))))
phdf<-do.call(rbind,per_hour)
sum_of_weights<-sum(phdf$num_events)
sum_of_ndyad<-sum(phdf$num_dyads)
weighted_avge_dyad<-sum_of_weights/sum_of_ndyad   #average number of events observed per time period (conditional on individuals having at least one visit during the time period)


#Calculate an estimate of baseline rate of interaction (across whole sample) for just affiliate dyads
coop_only_affil<-coop_only[coop_only$is.affiliate>0,]
coop_only_affil$Hour<-floor(coop_only_affil$TIME/3600)
per_hour_affil<-lapply(split(coop_only_affil,coop_only_affil$Hour),function(x) data.frame(Hour=unique(x[,"Hour"]),num_indivs=length(unique(c(x[,"SOURCE"],x[,"TARGET"]))),num_events=nrow(x),num_dyads=length(unique(x[,"DYAD"]))))
phdf_affil<-do.call(rbind,per_hour_affil)
sum_of_weights_affil<-sum(phdf_affil$num_events)
sum_of_ndyad_affil<-sum(phdf_affil$num_dyads)
weighted_avge_dyad_affil<-sum_of_weights_affil/sum_of_ndyad_affil   #average number of affiliate dyads observed per time period (conditional on dyads being affiliated and having at least one visit during the time period)


#Calculate an estimate of baseline rate of interaction (across whole sample) for just non-affiliate dyads
coop_only_nonaffil<-coop_only[coop_only$is.affiliate==0,]
coop_only_nonaffil$Hour<-floor(coop_only_nonaffil$TIME/3600)
per_hour_nonaffil<-lapply(split(coop_only_nonaffil,coop_only_nonaffil$Hour),function(x) data.frame(Hour=unique(x[,"Hour"]),num_indivs=length(unique(c(x[,"SOURCE"],x[,"TARGET"]))),num_events=nrow(x),num_dyads=length(unique(x[,"DYAD"]))))
phdf_nonaffil<-do.call(rbind,per_hour_nonaffil)
sum_of_weights_nonaffil<-sum(phdf_nonaffil$num_events)
sum_of_ndyad_nonaffil<-sum(phdf_nonaffil$num_dyads)
weighted_avge_dyad_nonaffil<-sum_of_weights_nonaffil/sum_of_ndyad_nonaffil   #average number of affiliate dyads observed per time period (conditional on dyads being affiliated and having at least one visit during the time period)


#Calculate an estimate of baseline rate of interaction (across whole sample) for individuals engaging in successful events
success_only<-coop_only[coop_only$TYPE=="COOP_SUCCESS",]
success_only$hour_success<-floor(success_only$TIME/3600)
success_per_hour<-lapply(split(success_only,success_only$hour_success),function(x) data.frame(Hour=unique(x[,"Hour"]),num_indivs=length(unique(c(x[,"SOURCE"],x[,"TARGET"]))),num_events=nrow(x),num_dyads=length(unique(x[,"DYAD"]))))
phdf_success<-do.call(rbind,success_per_hour)
phdf_success$num_events2<-as.numeric(phdf_success[,"num_events"])*2
sum_of_weights_s<-sum(phdf_success$num_events2)
sum_of_nindiv_s<-sum(phdf_success$num_indivs)
weighted_avge_indiv_s<-sum_of_weights_s/sum_of_nindiv_s   #average number of individuals observed interacting successfully per time period (conditional on individuals having at least one successful event during the time period)

```




Figure 2:

```{r}
pv_list1b<-lapply(pred_list1b,function(x) data.frame(t(data.frame(x$PRED_VAL))))
pv_df1b<-do.call(rbind,pv_list1b)
PI_LOW1b<-apply(pv_df1b,2,function(x) quantile(x,probs=0.0125))  #Calculate lower bound of 95% prediction interval at each time point
MED_VAL1b<-apply(pv_df1b,2,function(x) quantile(x,probs=0.5))   #Calculate median predicted value at each time point
PI_HIGH1b<-apply(pv_df1b,2,function(x) quantile(x,probs=0.9875))  #Calculate upper bound of 95% prediction interval at each time point
plot_df1b<-pred_list1b[[1]][,c("repeat_fail_deg","repeat_success_deg")]
plot_df1b<-cbind(plot_df1b,PI_LOW=PI_LOW1b,PI_MED=MED_VAL1b,PI_HIGH=PI_HIGH1b)

plot_df1b$PI_LOW<-(plot_df1b$PI_LOW*weighted_avge_indiv_s)-weighted_avge_indiv_s  #Convert predictions from relative risk (multipliers) to estimate of increase/decrease in incidence rate relative to sample-wide estimate of baseline incidence rate.
plot_df1b$PI_MED<-(plot_df1b$PI_MED*weighted_avge_indiv_s)-weighted_avge_indiv_s
plot_df1b$PI_HIGH<-(plot_df1b$PI_HIGH*weighted_avge_indiv_s)-weighted_avge_indiv_s

indiv_partners_BW<-ggplot(plot_df1b,aes(repeat_fail_deg,repeat_success_deg)) + geom_tile(aes(fill=PI_MED)) + scale_fill_gradient(low="white",high="black") + scale_x_continuous(breaks=c(0,5,10)) + scale_y_continuous(breaks=c(0,5,10)) + theme_classic() + theme(legend.title=element_blank(),axis.text=element_text(size=7,family="sans"),axis.title=element_text(size=7,family="sans"),legend.text=element_text(size=7,family="sans")) + xlab("Number of different-class participants with which \n an individual has had multiple associations") + ylab("Number of same-class participants with which \n an individual has had multiple associations")

#ggsave(filename="indiv_partners_BW_naturespecs240722.png",plot=indiv_partners_BW,type="cairo",dpi=360,width=85,height=65,units="mm")

indiv_partners<-ggplot(plot_df1b,aes(repeat_fail_deg,repeat_success_deg)) + geom_tile(aes(fill=PI_MED)) + scale_fill_gradient(low="sky blue",high="dark orange") + scale_x_continuous(breaks=c(0,5,10)) + scale_y_continuous(breaks=c(0,5,10)) + theme_classic() + theme(legend.title=element_blank(),axis.text=element_text(size=7,family="sans"),axis.title=element_text(size=7,family="sans"),legend.text=element_text(size=7,family="sans")) + xlab("Number of different-class participants with which \n an individual has had multiple associations") + ylab("Number of same-class participants with which \n an individual has had multiple associations")

#ggsave(filename="indiv_partners_naturespecs240722.png",plot=indiv_partners,type="cairo",dpi=360,width=85,height=65,units="mm")

```





Figure 3 (trends in successful/unsuccessful association events over time, for both observed (unpermuted) and expected (permuted) data):

```{r}

#Unpermuted success/fail differential over course of experiment
diff.counter<-apply(coop_only,1,function(x) if(x["TYPE"]=="COOP_SUCCESS"){1} else if(x["TYPE"]=="COOP_FAIL"){-1})    #mark successful events as positive, unsuccessful as negative
plot_df_diff<-data.frame(EVENT=1:length(diff.counter),sf_diff=diff.counter,Day=coop_only$Day[coop_only$TYPE %in% c("COOP_SUCCESS","COOP_FAIL")])
plot_df_diff$Day<-plot_df_diff$Day-(min(plot_df_diff$Day)-1)    #Get Days since day of first interaction
tempfac<-as.factor(plot_df_diff$Day)
levels(tempfac)<-as.character(1:length(unique(plot_df_diff$Day)))
plot_df_diff$Day<-as.numeric(as.character(tempfac))
day_list<-lapply(split(plot_df_diff,plot_df_diff$Day),function(x) data.frame(Day=unique(x[,"Day"]),sf_diff=sum(x[,"sf_diff"]),nevents=nrow(x)))  #get daily success/fail differential
day_df<-do.call(rbind,day_list)
day_df$csum<-cumsum(day_df$sf_diff)  #get cumulative sum of daily success/fail differential

#permuted success/fail differential over course of experiment
#load("~/DB_experiments/Files for publication/Data/perc_store_list.RData")
csum_only<-lapply(perc_store_list,function(x) x$csum)  #extract (only the) cumulative success/fail sums pertaining to each permuted dataset
csum_mat<-do.call(cbind,csum_only)   #Combine all cumulative differentials into a single data structure
PI_LOW<-apply(csum_mat,1,function(x) quantile(x,probs=0.025))   #Calculate lower bound of 95% interval of permuted success/fail differential for each day of the experiment
PI_MED<-apply(csum_mat,1,function(x) quantile(x,probs=0.5))     #Calculate median permuted success/fail differential for each day of the experiment
PI_HIGH<-apply(csum_mat,1,function(x) quantile(x,probs=0.975))   #Calculate upper bound of 95% interval of permuted success/fail differential for each day of the experiment
expected_sf<-data.frame(Day=1:length(PI_LOW),PI_LOW=PI_LOW,PI_MED=PI_MED,PI_HIGH=PI_HIGH)


#data for events per day bar plots (number of successful and unsuccesful events per day)
f_df<-plot_df_diff[which(plot_df_diff$sf_diff==-1),]    #All unsuccessful events
s_df<-plot_df_diff[which(plot_df_diff$sf_diff==1),]      #All successful events
day_lists<-lapply(split(s_df,s_df$Day),function(x) data.frame(Day=unique(x[,"Day"]),nevents_s=nrow(x)))   #Get count of number of successful events per day
day_listf<-lapply(split(f_df,f_df$Day),function(x) data.frame(Day=unique(x[,"Day"]),nevents_f=nrow(x)))  #Get count of number of unsuccessful events per day
dfs<-do.call(rbind,day_lists)
dff<-do.call(rbind,day_listf)
dfs2<-data.frame(Day=c(1,2,3,4,5,8,10,11,12,13,15,25),nevents_s=c(0,0,0,0,0,0,0,0,0,0,0,0))#replace missing values with zeros (i.e. days without successful events)
dfs_fin<-rbind(dfs2,dfs)
dff2<-data.frame(Day=c(9,14,19,21),nevents_f=c(0,0,0,0))  #replace missing values with zeros (i.e. days without unsuccessful events)
dff_fin<-rbind(dff,dff2)
day_df2<-merge(day_df,dfs_fin,by="Day")
day_df3<-merge(day_df2,dff_fin,by="Day")   
day_df3$nevents_f<-day_df3$nevents_f*-1   #Convert counts of unsuccessful events from negative to positive (sign needs to be removed for plotting)

#Colour plot of trends in successful/unsuccessful events over the period of the experiment
timeplot_trends_colour<-ggplot() + geom_col(data=day_df3,aes(Day,nevents_s),fill="white",colour="gray50") + geom_col(data=day_df3,aes(Day,nevents_f),fill="white",colour="gray50") + geom_hline(yintercept=0) + geom_line(data=expected_sf,aes(Day,PI_MED),colour="red",lwd=0.5) + geom_ribbon(data=expected_sf,aes(x=Day,ymin=PI_LOW,ymax=PI_HIGH),fill="red",alpha=0.25) + geom_line(data=day_df,aes(Day,csum),colour="black",lwd=1) + theme_classic() + ylab("Success/Fail differential") + xlab("Days since beginning of experiment") + theme(axis.text=element_text(size=7,family="sans"),axis.title=element_text(size=7,family="sans"))

#ggsave(filename="timeplot_trends_colour_naturespecs.png",plot=timeplot_trends_colour,type="cairo",dpi=360,width=85,height=50,units="mm")

#Black-and-white plot
timeplot_trends_BW<-ggplot() + geom_col(data=day_df3,aes(Day,nevents_s),fill="white",colour="gray50") + geom_col(data=day_df3,aes(Day,nevents_f),fill="white",colour="gray50") + geom_hline(yintercept=0) + geom_ribbon(data=expected_sf,aes(x=Day,ymin=PI_LOW,ymax=PI_HIGH),alpha=0.35) + geom_line(data=day_df,aes(Day,csum),colour="black",lwd=1) + geom_line(data=expected_sf,aes(Day,PI_MED),colour="black",lwd=0.5,lty="twodash") + theme_classic() + ylab("Success/Fail differential") + xlab("Days since beginning of experiment") + theme(axis.text=element_text(size=7,family="sans"),axis.title=element_text(size=7,family="sans"))

#ggsave(filename="timeplot_trends_BW_naturespecs.png",plot=timeplot_trends_BW,type="cairo",dpi=360,width=85,height=50,units="mm")


```





Figure 4:

```{r}
#load("~/DB_experiments/Files for publication/Data/pred_list1a030721.RData")
#load("~/DB_experiments/Files for publication/Data/pred_list1b030721.RData")

#affiliates
pv_list3a<-lapply(pred_list3a,function(x) data.frame(t(data.frame(x$PRED_VAL))))
pv_df3a<-do.call(rbind,pv_list3a)
PI_LOW3a<-apply(pv_df3a,2,function(x) quantile(x,probs=0.025))   #Get lower bounds of 95% prediction intervals (for different categories of prior experience)
MED_VAL3a<-apply(pv_df3a,2,function(x) quantile(x,probs=0.5))     #Get median predicted values (for different categories of prior experience)
PI_HIGH3a<-apply(pv_df3a,2,function(x) quantile(x,probs=0.975))   #Get upper bounds of 95% prediction intervals (for different categories of prior experience)
plot_df3a<-pred_list3a[[1]][,c("same_group","dyad.coop.cat")]
plot_df3a<-cbind(plot_df3a,PI_LOW=PI_LOW3a,MED_VAL=MED_VAL3a,PI_HIGH=PI_HIGH3a)
plot_df3a$PI_LOW<-plot_df3a$PI_LOW*weighted_avge_dyad_affil  #Convert predictions from relative risk (multipliers) to estimate of increase/decrease in incidence rate relative to sample-wide estimate of baseline incidence rate.
plot_df3a$MED_VAL<-plot_df3a$MED_VAL*weighted_avge_dyad_affil
plot_df3a$PI_HIGH<-plot_df3a$PI_HIGH*weighted_avge_dyad_affil


plot_df3a$dyad.coop.cat<-apply(plot_df3a,1,function(x) if(x["dyad.coop.cat"]=="ARE_UNFAMILIAR"){"0"} else if(x["dyad.coop.cat"]=="FAMILIAR_1TO5") {"1-5"} else if(x["dyad.coop.cat"]=="FAMILIAR_6PLUS"){"6+"})


#non-affiliates
pv_list3b<-lapply(pred_list3b,function(x) data.frame(t(data.frame(x$PRED_VAL))))
pv_df3b<-do.call(rbind,pv_list3b)
PI_LOW3b<-apply(pv_df3b,2,function(x) quantile(x,probs=0.025))
MED_VAL3b<-apply(pv_df3b,2,function(x) quantile(x,probs=0.5))
PI_HIGH3b<-apply(pv_df3b,2,function(x) quantile(x,probs=0.975))
plot_df3b<-pred_list3b[[1]][,c("same_group","dyad.coop.cat")]
plot_df3b<-cbind(plot_df3b,PI_LOW=PI_LOW3b,MED_VAL=MED_VAL3b,PI_HIGH=PI_HIGH3b)
plot_df3b$PI_LOW<-plot_df3b$PI_LOW*weighted_avge_dyad_nonaffil
plot_df3b$MED_VAL<-plot_df3b$MED_VAL*weighted_avge_dyad_nonaffil
plot_df3b$PI_HIGH<-plot_df3b$PI_HIGH*weighted_avge_dyad_nonaffil
plot_df3b$dyad.coop.cat<-apply(plot_df3b,1,function(x) if(x["dyad.coop.cat"]=="ARE_UNFAMILIAR"){"0"} else if(x["dyad.coop.cat"]=="FAMILIAR_1TO5") {"1-5"} else if(x["dyad.coop.cat"]=="FAMILIAR_6PLUS"){"6+"})


#Note, the following ggplot code for plotting affiliate and non-affiliate data is the same. Un-comment the relevant lines (sdf & fdf) below to choose whether to plot affiliate or non-affiliate predictions:

#sdf<-plot_df3a[plot_df3a$same_group==1,]  #for plotting affiliates
#fdf<-plot_df3a[plot_df3a$same_group==0,]  #for plotting affiliates
#reference_line_value<-weighted_avge_dyad_affil  #for plotting affiliates

sdf<-plot_df3b[plot_df3b$same_group==1,]   #for plotting non-affiliates
fdf<-plot_df3b[plot_df3b$same_group==0,]   #for plotting non-affiliates
reference_line_value<-weighted_avge_dyad_nonaffil  #for plotting non-affiliates



#Plot in colour
dyads_colour<-ggplot() + geom_linerange(data=fdf,aes(x=dyad.coop.cat,ymin=PI_LOW,ymax=PI_HIGH),colour="sky blue",position=position_nudge(-0.05,0),size=1) + geom_linerange(data=sdf,aes(x=dyad.coop.cat,ymin=PI_LOW,ymax=PI_HIGH),colour="dark orange",position=position_nudge(0.05,0),size=1) + geom_point(data=fdf,aes(x=dyad.coop.cat,y=MED_VAL),colour="navy blue",position=position_nudge(-0.05,0),size=1.5,shape=21,fill="sky blue") + geom_point(data=sdf,aes(x=dyad.coop.cat,y=MED_VAL),colour="darkorange4",position=position_nudge(0.05,0),size=1.5,shape=21,fill="dark orange") + theme_classic() + xlab("Number of previous associations between members of a dyad") + ylab("Expected association rate (events per hour)") + geom_hline(yintercept=reference_line_value,lty=2) + theme(axis.text=element_text(size=7,family="sans"),axis.title=element_text(size=7,family="sans"))

ggsave(filename="nonaffil_dyads_colour_naturespecs070822.png",plot=dyads_colour,type="cairo",dpi=360,width=85,height=60,units="mm")
#ggsave(filename="affil_dyads_colour_naturespecs070822.png",plot=dyads_colour,type="cairo",dpi=360,width=85,height=60,units="mm")

#Black-and-white
dyads_BW<-ggplot() + geom_linerange(data=fdf,aes(x=dyad.coop.cat,ymin=PI_LOW,ymax=PI_HIGH),colour="black",position=position_nudge(-0.05,0),size=1) + geom_linerange(data=sdf,aes(x=dyad.coop.cat,ymin=PI_LOW,ymax=PI_HIGH),colour="black",position=position_nudge(0.05,0),size=1) + geom_point(data=fdf,aes(x=dyad.coop.cat,y=MED_VAL),colour="black",position=position_nudge(-0.05,0),size=1.5,shape=21,fill="black") + geom_point(data=sdf,aes(x=dyad.coop.cat,y=MED_VAL),colour="black",position=position_nudge(0.05,0),size=1.5,shape=21,fill="white") + theme_classic() + xlab("Number of previous interactions between members of a dyad") + ylab("Expected association rate (events per hour)") + geom_hline(yintercept=reference_line_value,lty=2) +  theme(axis.text=element_text(size=7,family="sans"),axis.title=element_text(size=7,family="sans"))

ggsave(filename="nonaffil_dyads_BW_naturespecs070822.png",plot=dyads_BW,type="cairo",dpi=360,width=85,height=60,units="mm")
#ggsave(filename="affil_dyads_BW_naturespecs070822.png",plot=dyads_BW,type="cairo",dpi=360,width=85,height=60,units="mm")

```








Extended Data Figure 2:

```{r}

coop_only$source.num.events<-coop_only$source.num.starts + coop_only$source.num.joins  #calculate cumulative count of all previous events (as both source and target) that each individual listed as a source at a given time point has engaged in.
exp.list<-lapply(split(coop_only,coop_only$SOURCE),function(x) if(nrow(x)) {data.frame(SOURCE=unique(x$SOURCE),NUM_EVENTS=max(x$source.num.events))})  ##for each individual that engaged in at least one event as a target, calculate its total (sample-wide) number of association events 
exp_df<-do.call(rbind,exp.list)
colnames(exp_df)<-c("ID","NUM_EVENTS")
exp_df$NUM_EVENTS<-exp_df$NUM_EVENTS+1

coop_only$target.num.events<-coop_only$target.num.starts + coop_only$target.num.joins #calculate cumulative count of all previous events (as both source and target) that each individual listed as a target at a given time point has engaged in.
exp.list.t<-lapply(split(coop_only,coop_only$TARGET),function(x) if(nrow(x)) {data.frame(TARGET=unique(x$TARGET),NUM_EVENTS=max(x$target.num.events))})   #for each individual that engaged in at least one event as a target, calculate its total (sample-wide) number of association events 
exp_dft<-do.call(rbind,exp.list.t)
t_only<-exp_dft[which(!exp_dft[,1] %in% exp_df[,1]),]   #filter to get only individuals that were observed as targets but not also as sources (to avoid duplication)
colnames(t_only)<-c("ID","NUM_EVENTS")
t_only$NUM_EVENTS<-t_only$NUM_EVENTS+1

allexp<-rbind(exp_df,t_only)   #Combine source and target event counts. Note, calculation performed for both sources and targets as some individuals were only observed as either a source or a target.
exp_store<-c()
for(i in 1:50){exp_store<-c(exp_store,sum(allexp$NUM_EVENTS>i))}   #Calculate the number of individuals that participated in more than i (where i ranges from 1 to 50) association events.
plot_df<-data.frame(NUM_EVENTS=1:50,NUM_INDIVS=exp_store)

#Plot number of individuals that participated in greater than a given number of association events
exp_indivs<-ggplot(aes(NUM_EVENTS,NUM_INDIVS),data=plot_df) + geom_line() + theme_classic() + xlab("Threshold number of association events") + ylab("Number of individuals") + ylim(0,150) + geom_vline(xintercept=3.5,linetype="dashed") + geom_vline(xintercept=21,linetype="dotted") + theme(axis.text=element_text(size=7,family="sans"),axis.title=element_text(size=7,family="sans"))

ggsave(filename="exp_indivs_280822.png",plot=exp_indivs,type="cairo",dpi=360,width=60,height=50,units="mm")

exp.list.dyad<-lapply(split(coop_only,coop_only$DYAD),function(x) if(nrow(x)) {data.frame(DYAD=unique(x$DYAD),NUM_EVENTS=max(x$dyad.coop.count),IS_AFFIL=max(x$is.affiliate),SAME_GROUP=unique(x$same_group))})  #For each dyad, get total sample-wide number of association events along with dyad characteristics (affiliation, class combination)
exp_df.dyad<-do.call(rbind,exp.list.dyad)
exp_df.dyad$NUM_EVENTS<-exp_df.dyad$NUM_EVENTS+1

exp_store.affildyad<-c()
exp_store.nonaffildyad<-c()
for(i in 1:50){
  exp_store.affildyad<-c(exp_store.affildyad,sum(exp_df.dyad[exp_df.dyad$IS_AFFIL==1,"NUM_EVENTS"]>i))   #Calculate how many affiliate dyads participated in greater than a given number (i) of association events
  exp_store.nonaffildyad<-c(exp_store.nonaffildyad,sum(exp_df.dyad[exp_df.dyad$IS_AFFIL==0,"NUM_EVENTS"]>i)) #Calculate how many non-affiliate dyads participated in greater than a given number (i) of association events
}
plot_df.affildyad<-data.frame(NUM_EVENTS=1:50,NUM_DYADS=exp_store.affildyad)
plot_df.nonaffildyad<-data.frame(NUM_EVENTS=1:50,NUM_DYADS=exp_store.nonaffildyad)

#Plot number of affiliate dyads that participated in greater than a given number of association events
exp_dyads_affil<-ggplot(aes(NUM_EVENTS,NUM_DYADS),data=plot_df.affildyad) + geom_line() + theme_classic() + xlab("Threshold number of association events") + ylab("Number of affiliated dyads") +  theme(axis.text=element_text(size=7,family="sans"),axis.title=element_text(size=7,family="sans")) + ylim(0,20)

ggsave(filename="exp_affildyads_280822.png",plot=exp_dyads_affil,type="cairo",dpi=360,width=60,height=50,units="mm")

#Plot number of non-affiliate dyads that participated in greater than a given number of association events
exp_dyads_nonaffil<-ggplot(aes(NUM_EVENTS,NUM_DYADS),data=plot_df.nonaffildyad) + geom_line() + theme_classic() + xlab("Threshold number of association events") + ylab("Number of unaffiliated dyads") + geom_vline(xintercept=4,linetype="dashed") + geom_vline(xintercept=9,linetype="dotted") + theme(axis.text=element_text(size=7,family="sans"),axis.title=element_text(size=7,family="sans"))

ggsave(filename="exp_nonaffildyads_280822.png",plot=exp_dyads_nonaffil,type="cairo",dpi=360,width=60,height=50,units="mm")

```






Extended Data Figure 3:

```{r}

#Initialization of vectors/variables for use in loop
affil_same_event_store<-c()
affil_diff_event_store<-c()
naffil_same_event_store<-c()
naffil_diff_event_store<-c()
affil_same_dyad_store<-c()
affil_diff_dyad_store<-c()
naffil_same_dyad_store<-c()
naffil_diff_dyad_store<-c()
affil_same_event_counter<-0
affil_diff_event_counter<-0
naffil_same_event_counter<-0
naffil_diff_event_counter<-0
affil_same_dyad_counter<-0
affil_diff_dyad_counter<-0
naffil_same_dyad_counter<-0
naffil_diff_dyad_counter<-0


for(i in 1:nrow(coop_only)){      #for each association event...
  
  #cumulative counts of number of events between same-class affiliates and number of this type of dyad
  if(coop_only[i,"is.affiliate"]>0 && coop_only[i,"same_group"]==1) {
    affil_same_event_counter<-affil_same_event_counter+1
    if(coop_only[i,"dyad.coop.count"]==0){
      affil_same_dyad_counter<-affil_same_dyad_counter+1
    }
    
  #cumulative counts of number of events between different-class affiliates and number of this type of dyad
  }
  if(coop_only[i,"is.affiliate"]>0 && coop_only[i,"same_group"]==0) {
    affil_diff_event_counter<-affil_diff_event_counter+1
    if(coop_only[i,"dyad.coop.count"]==0){
      affil_diff_dyad_counter<-affil_diff_dyad_counter+1
    }
  }
  
  #cumulative counts of number of events between same-class non-affiliates and number of this type of dyad
  if(coop_only[i,"is.affiliate"]==0 && coop_only[i,"same_group"]==1) {
    naffil_same_event_counter<-naffil_same_event_counter+1
    if(coop_only[i,"dyad.coop.count"]==0){
      naffil_same_dyad_counter<-naffil_same_dyad_counter+1
    }
  }
  
  #cumulative counts of number of events between different-class non-affiliates and number of this type of dyad
  if(coop_only[i,"is.affiliate"]==0 && coop_only[i,"same_group"]==0) {
    naffil_diff_event_counter<-naffil_diff_event_counter+1
    if(coop_only[i,"dyad.coop.count"]==0){
      naffil_diff_dyad_counter<-naffil_diff_dyad_counter+1
    }
  }
  
  #store cumulative counts
  affil_same_event_store<-c(affil_same_event_store,affil_same_event_counter)
  affil_diff_event_store<-c(affil_diff_event_store,affil_diff_event_counter)
  naffil_same_event_store<-c(naffil_same_event_store,naffil_same_event_counter)
  naffil_diff_event_store<-c(naffil_diff_event_store,naffil_diff_event_counter)
  affil_same_dyad_store<-c(affil_same_dyad_store,affil_same_dyad_counter)
  affil_diff_dyad_store<-c(affil_diff_dyad_store,affil_diff_dyad_counter)
  naffil_same_dyad_store<-c(naffil_same_dyad_store,naffil_same_dyad_counter)
  naffil_diff_dyad_store<-c(naffil_diff_dyad_store,naffil_diff_dyad_counter)
  
}

as_rate<-affil_same_event_store/affil_same_dyad_store   #Instantaneous number of events per dyad for same-class affiliates
adf_rate<-affil_diff_event_store/affil_diff_dyad_store  #Instantaneous number of events per dyad for different-class affiliates
nas_rate<-naffil_same_event_store/naffil_same_dyad_store #Instantaneous number of events per dyad for same-class non-affiliates
nadf_rate<-naffil_diff_event_store/naffil_diff_dyad_store  #Instantaneous number of events per dyad for different-class non-affiliates
plot_df<-data.frame(EVENT=1:3117,as_rate,adf_rate,nas_rate,nadf_rate,AS_DYADS=affil_same_dyad_store,ADF_DYADS=affil_diff_dyad_store,NAS_DYADS=naffil_same_dyad_store,NADF_DYADS=naffil_diff_dyad_store)

plot_df$A_DYADS_TOT<-plot_df$AS_DYADS + plot_df$ADF_DYADS  #cumulative count of total number of affiliated dyads
plot_df$NA_DYADS_TOT<-plot_df$NAS_DYADS + plot_df$NADF_DYADS   #cumulative count of total number of non-affiliated dyads
plot_df$NA_DYADS_TOT<-plot_df$NA_DYADS_TOT/100   #transformation required for scaling of secondary plotting axis
plot_df$NAS_DYADS<-plot_df$NAS_DYADS/100     #transformation required for scaling of secondary plotting axis


#plot events per dyad (and dyad numbers) for affiliated dyads
affil_dyadrates<-ggplot() + geom_col(data=plot_df,aes(EVENT,A_DYADS_TOT),colour="gray90") + geom_col(data=plot_df,aes(EVENT,AS_DYADS),colour="gray70") + geom_line(data=plot_df,aes(EVENT,as_rate),colour="dark orange") + geom_line(data=plot_df,aes(EVENT,adf_rate),colour="sky blue") + theme_classic() + theme(axis.text=element_text(size=7,family="sans"),axis.title=element_text(size=7,family="sans")) + xlab("Number of association events since \n beginning of experiment") + ylab("Mean number of association \n events per dyad") + scale_y_continuous(sec.axis=sec_axis(trans=~.*1,name="Dyad count"))

#ggsave(filename="affil_dyadrates260622.png",plot=affil_dyadrates,type="cairo",dpi=360,width=85,height=55,units="mm")

#plot events per dyad (and dyad numbers) for non-affiliated dyads
naffil_dyadrates<-ggplot() + geom_col(data=plot_df,aes(EVENT,NA_DYADS_TOT),colour="gray90") + geom_col(data=plot_df,aes(EVENT,NAS_DYADS),colour="gray70") + geom_line(data=plot_df,aes(EVENT,nas_rate),colour="dark orange") + geom_line(data=plot_df,aes(EVENT,nadf_rate),colour="sky blue") + theme_classic() + scale_y_continuous(sec.axis=sec_axis(trans=~.*100,name="Dyad count")) + theme(axis.text=element_text(size=7,family="sans"),axis.title=element_text(size=7,family="sans")) + xlab("Number of association events since \n beginning of experiment") + ylab("Mean number of association \n events per dyad")

#ggsave(filename="naffil_dyadrates260622.png",plot=naffil_dyadrates,type="cairo",dpi=360,width=85,height=55,units="mm")

```





Extended Data Figure 4:

```{r}

pv_list4_temp1<-lapply(pred_list4,function(x) cbind(x,PRED_VAL2=x$PRED_VAL*weighted_avge_dyad))  #Transform predicted values from relative risk (multiplier) to increase/decrease in number of events per unit time relative to sample-wide baseline.
pv_list4<-lapply(pv_list4_temp1,function(x) data.frame(t(data.frame(x$PRED_VAL2))))
pv_df4<-do.call(rbind,pv_list4)
PI_LOW4<-apply(pv_df4,2,function(x) quantile(x,probs=0.025))  #Calculate lower bound of 95% prediction interval at each time point
MED_VAL4<-apply(pv_df4,2,function(x) quantile(x,probs=0.5))   #Calculate median predicted value at each time point
PI_HIGH4<-apply(pv_df4,2,function(x) quantile(x,probs=0.975))  #Calculate upper bound of 95% prediction interval at each time point
plot_df4<-pv_list4_temp1[[1]][,c("network.num.coop","DAY","success.closure")]
plot_df4<-cbind(plot_df4,PI_LOW=PI_LOW4,MED_VAL=MED_VAL4,PI_HIGH=PI_HIGH4)
plot_df4$DAY<-plot_df4$DAY-(min(plot_df4$DAY)-1)    #Get Days since day of first interaction
tempfac<-as.factor(plot_df4$DAY)
levels(tempfac)<-as.character(1:length(unique(plot_df4$DAY)))
plot_df4$DAY<-as.numeric(as.character(tempfac))

plot_df_s0<-plot_df4[plot_df4$success.closure==0,]
plot_df_s10<-plot_df4[plot_df4$success.closure==3,]

closure_plot<-ggplot() + geom_line(data=plot_df_s10,aes(DAY,MED_VAL),colour="red",lwd=1) + geom_ribbon(data=plot_df_s10,aes(x=DAY,ymin=PI_LOW,ymax=PI_HIGH),fill="red",alpha=0.2) + geom_line(data=plot_df_s0,aes(DAY,MED_VAL),colour="blue",lwd=1) + geom_ribbon(data=plot_df_s0,aes(x=DAY,ymin=PI_LOW,ymax=PI_HIGH),fill="blue",alpha=0.2) + theme_classic() + xlab("Days since beginning of experiment") + ylab("Predicted association rate \n (events per hour)") + theme(axis.text=element_text(size=7,family="sans"),axis.title=element_text(size=7,family="sans"))

#ggsave(filename="closure_140822.png",plot=closure_plot,type="cairo",dpi=360,width=65,height=50,units="mm")

```


