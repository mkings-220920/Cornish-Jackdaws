---
title: "Darwin Board experiment REMs"
author: "MK"
date: "17 October 2020"
output:
  word_document: default
  html_document: default
---

Load required packages and functions

```{r}
setwd("C:\\Users\\Mike\\Documents\\DB_experiments\\Files for publication\\Data")
library(survival)
library(scales)
library(ggplot2)
source("C:\\Users\\Mike\\Documents\\DB_experiments\\Files for publication\\Scripts\\get_dyad_labels.R")   #A function for adding a dyad label column to a REM dataset
source("C:\\Users\\Mike\\Documents\\DB_experiments\\Files for publication\\Scripts\\repeat_degree.R") #A function for calculating the number of group members with which an individual has had multiple associations. Returns a time-varying covariate for use in REMs.
```


Individual-level hypotheses (Conditioned on Source). The input files for these analyses comprise permuted REM datasets produced by permutation of TARGET labels only (Perm 2 - Independent permutation of SOURCE and TARGET labels; see Supplementary Fig. 3b) and subsequently processed in Eventnet 0.5.2

 - Model 1: The relationship between individuals' quantity of past events with familiar same-class and different-class partners and future success.
 
 - Model 2: The relationship between individuals' number of same-class and different-class partners, with which they have associated on multiple occasions, and future success. 
 
 Predicted values used for plotting (Figure 2) generated.

```{r}
#To re-run the analysis in the paper, set working directory to: .../Eventnet_output/ptests_perm2_EventnetOutput

feed_files<-list.files(no..=TRUE)  #Get list of files within current directory
coop_indicator<-unlist(sapply(feed_files,function(x) grepl("COOP_EVENTS",x)))   #Find file names containing "COOP_EVENTS" (Eventnet cooperation observations output)
cond_files<-feed_files[coop_indicator]   #Filter list of all file names to just COOP_EVENTS files
cond_list1<-list()
cond_list2<-list()
pred_list1<-list()
pred_list2<-list()

pred_df2<-as.data.frame(expand.grid(0:10,0:10))
colnames(pred_df2)<-c("repeat_success_deg","repeat_fail_deg")

for(i in 1:length(cond_files))  #loop over files within subfolder
{
  print(i)
  coop.events<-read.csv(cond_files[i],header=T,row.names=NULL)  #read in current Eventnet output file
  coop.events$DAY<-floor(coop.events$TIME/(60*60*24))
  coop.events$TIME<-rescale(coop.events$TIME)
  coop.events$same_group<-apply(coop.events,1,function(x) if(as.numeric(x["source.is.groupA"])==as.numeric(x["target.is.groupA"])){1} else {0}) #Check the group assignments of each SOURCE and TARGET pair and create a binary indicator of whether the pair belonged to the same, or different, treatment groups
  coop.events$target.coop.count<-coop.events$target.num.success + coop.events$target.num.fails   #Calculate total number of interactions engaged in by the TARGET
  coop.events$target.degree<-coop.events$target.degree.success + coop.events$target.degree.failure   #Calculate overall (unweighted) degree
  coop.events$event.indicator<-apply(coop.events,1,function(x) if(x["TYPE"]=="NON-EVENT"){0} else {1})   #Make sure that events (1) and non-events (0) have separate labels
  
  coop.events$DYAD<-get_dyad_labels(coop.events)
  coop.events$target_repeat_success_count<-coop.events$target.num.success-coop.events$target.degree.success
  coop.events$target_repeat_fail_count<-coop.events$target.num.fails-coop.events$target.degree.failure
  coop.events<-repeat_degree(coop.events)
  
  success.locs.temp<-which(coop.events$TYPE=="COOP_SUCCESS")
  success.locs<-c(success.locs.temp,(success.locs.temp + 1))
  success.locs<-sort(success.locs)
  coop.events.success<-coop.events[success.locs,]
  my.surv.coop.success<-Surv(time=rep(1,dim(coop.events.success)[1]),event=coop.events.success$event.indicator)
  
  #Model 1:
  tempw1<-tryCatch(perm.model.coop<-coxph(my.surv.coop.success ~ 
                                target_repeat_success_count*target_repeat_fail_count
                              + strata(DAY) 
                             , data = coop.events.success),warning=function(w) return("W"))
  
  
  if(is.object(tempw1)){
    cond_list1[[i]]<-as.data.frame(t(tempw1$coefficients))
  } else {
    cond_list1[[i]]<-NULL
  }
  
  
   #Model 2:
   tempw2<-tryCatch(perm.model.coop<-coxph(my.surv.coop.success ~ 
                               repeat_success_deg*repeat_fail_deg 
                              + strata(DAY) 
                             , data = coop.events.success),warning=function(w) return("W"))
   
   
  if(is.object(tempw2)){
    cond_list2[[i]]<-as.data.frame(t(tempw2$coefficients))
    tempdf2<-cbind(pred_df2,as.data.frame(predict(tempw2,newdata=pred_df2,type="risk",reference="sample")))
    colnames(tempdf2)[ncol(tempdf2)]<-"PRED_VAL"               
    pred_list2[[i]]<-tempdf2
  } else {
    cond_list2[[i]]<-NULL
    pred_list2[[i]]<-NULL
  }
  
}

cond_df_cs_1<-do.call(rbind,cond_list1)  #Combine coefficients from each permuted REM for a given model type to get a single dataframe of pREM coefficients (with nrow == nperm)
cond_df_cs_2<-do.call(rbind,cond_list2)


#Determine median coefficient value and 97.5% confidence interval from quantiles of pREM coefficient distribution. 97.5% CI used rather than 95% CI due to multiple testing (similar hypothesis tested using two models). As p-values are not being calculated, p-value thresholds are not adjusted to account for this (i.e. Bonferroni correction), rather this adjustment of confidence intervals is used to account for the multiple testing.

quant_list1<-apply(cond_df_cs_1,2,function(x) data.frame(CI_LOW=quantile(x,probs=0.0125),MED=quantile(x,probs=0.5),CI_HIGH=quantile(x,probs=0.9875),MINIMUM=min(x),MAXIMUM=max(x),I.R.=exp(quantile(x,probs=0.5))))
quant_df1<-do.call(rbind,quant_list1)
write.csv(quant_df1,"cond_cs_quantdf_1.csv")

quant_list2<-apply(cond_df_cs_2,2,function(x) data.frame(CI_LOW=quantile(x,probs=0.0125),MED=quantile(x,probs=0.5),CI_HIGH=quantile(x,probs=0.9875),MINIMUM=min(x),MAXIMUM=max(x),I.R.=exp(quantile(x,probs=0.5))))
quant_df2<-do.call(rbind,quant_list2)
write.csv(quant_df2,"cond_cs_quantdf_2.csv")

```



Dyad & Network-level hypotheses. The input files for these analyses comprise permuted REM datasets produced by permutation of all identity labels (Perm 1 - Non-independent permutation of SOURCE and TARGET labels; see Supplementary Fig. 3a) and subsequently processed in Eventnet 0.5.2


 - Model 3: Changes in association rates over the course of the experiment (for different types of dyad: same/diff treatment group, affiliated/not affiliated, familiar/unfamiliar). 
 - Model 4: Differences in association rate attributable to properties of dyads (number of previous events, same/diff treatment group) for affiliates.

 - Model 5: Differences in association rate attributable to properties of dyads (number of previous events, same/diff treatment group) for non-affiliates.

 - Model 8: Changes in (local) network structure over the course of the experiment, as measured by triadic closure (closure of triads: interaction of two individuals that have previously both interacted with a common third individual).  Baseline (i.e. irrespective of experimental design) number of common associates per dyad and number of same-class associates per same-class dyad are modelled. 
 
```{r}
#To re-run the analysis in the paper, set working directory to: .../Eventnet_output/ptests_perm1_EventnetOutput

feed_files<-list.files(no..=TRUE)   #Get list of files within current directory
coop_indicator<-unlist(sapply(feed_files,function(x) grepl("COOP_EVENTS",x)))   #Find file names containing "COOP_EVENTS" (Eventnet cooperation observations output)
coop_files<-feed_files[coop_indicator]    #Filter list of all file names to just COOP_EVENTS files
cox_trt_list<-list()   #list for storing coefficients from model 3
cox_dyad_list_affil<-list()   #list for storing coefficients from model 4  
cox_dyad_list_nonaffil<-list() #list for storing coefficients from model 5
cox_tri_list<-list()    #list for storing coefficients from model 8
pred_list4<-list()       #list for storing predicted values from model 4
pred_list5<-list()        #list for storing predicted values from model 5
pred_list8<-list()         #list for storing predicted values from model 8
perc_store<-c()            #list for storing overall proportion of 'non-events'that were successes. 
perc_store_list<-list()      #list for storage of cumulative sum of per-day success-fail differential (from 'non-events'). See 'permuted' in Figure 3.


for(i in 1:length(coop_files))  #loop over all cooperation files in directory
{
  print(i)
  coop.events<-read.csv(coop_files[i],header=T,row.names=NULL)  #read in current Eventnet output file
  coop.events$DAY<-floor(coop.events$TIME/(60*60*24))
  coop.events$same_group<-apply(coop.events,1,function(x) if(as.numeric(x["source.is.groupA"])==as.numeric(x["target.is.groupA"])){1} else {0}) #Check the group assignments of each SOURCE and TARGET pair and create a binary indicator of whether the pair belonged to the same, or different, treatment groups.
  #coop.events$lock.bool<-as.numeric(unlist(apply(coop.events,1,function(x) context_clip[which(as.numeric(context_clip[,"TIME"]) %in% as.numeric(x["TIME"]))[1],"lock_bool"])))   #add task state info (lockout == 1, non-lockout == 0) for each event
  coop.events$TIME_rescaled<-rescale(coop.events$TIME)  #rescale to make parameter more interpretable
  coop.events$dyad.coop.count<-coop.events$dyad.success.count + coop.events$dyad.fail.count    #Get a single variable containing info on number of events engaged in by a dyad.
  coop.events$dyad.coop.cat<-sapply(as.numeric(coop.events$dyad.coop.count),function(x) if(x<1){"ARE_UNFAMILIAR"} else if(x>0 && x<6){"FAMILIAR_1TO5"} else {"FAMILIAR_6PLUS"})     #Split count of dyadic cooperation events into three categories (ARE_UNFAMILIAR = dyad has not had a previous event; FAMILIAR_1TO5 = dyad has had between one and five previous events; FAMILIAR_6PLUS = dyad has had six or more previous events)
  coop.events$is.affiliate<-sapply(coop.events$is.affiliate,function(x) if(x>0){1} else{0})    #ensure that affiliation indicator is 0/1 (affiliated==1)
  coop.events$dyad.has.previous<-coop.events$dyad.has.previous.fail + coop.events$dyad.has.previous.success  #Single variable indicating whether a dyad has had at least one previous interaction
  coop.events$dyad.has.previous<-apply(coop.events,1,function(x) if(as.numeric(x["dyad.has.previous"])>0){1} else {0})  #ensure that dyad.has.previous indicator is 0/1 (has had a previous event == 1)
  coop.events$event.indicator<-apply(coop.events,1,function(x) if(x["TYPE"]=="NON-EVENT"){0} else {1})   #Make sure that events (1) and non-events (0) have separate labels
  my.surv.coop<-Surv(time = rep(1,dim(coop.events)[1]), event = coop.events$event.indicator)
  
  #Model 3: Change in likelihood of observing same/different class dyads over time
  tempw3<-tryCatch(perm.net.coop<-coxph(my.surv.coop ~ 
                                            network.num.coop*same_group 
                                            - network.num.coop
                                            + strata(DAY) 
                                            , data = coop.events),warning=function(w) return("W"))
    
    if(is.object(tempw3)){         #If the model has been fitted successfully (i.e. without warnings)
      cox_trt_list[[i]]<-as.data.frame(t(tempw3$coefficients))           #Store model coefficients as a dataframe in the current list element
    } else {
      cox_trt_list[[i]]<-NULL
    }
    
  
  
  
  #Model 4: Associations of affiliate dyads
  affil.locs.temp<-which(coop.events$is.affiliate>0 & coop.events$TYPE!="NON-EVENT")
  affil.locs<-c(affil.locs.temp,(affil.locs.temp + 1))
  affil.locs<-sort(affil.locs)
  coop.events.affil<-coop.events[affil.locs,]
  
  my.surv.coop.affil<-Surv(time = rep(1,dim(coop.events.affil)[1]), event = coop.events.affil$event.indicator)
  
  tempw4<-tryCatch(perm.dyad.coop<-coxph(my.surv.coop.affil ~ 
                                           same_group*dyad.coop.cat
                                             + strata(DAY) 
                                             , data = coop.events.affil),warning=function(w) return("W"))
    
    if(is.object(tempw4)){        #If the model has been fitted successfully (i.e. without warnings)
      cox_dyad_list_affil[[i]]<-as.data.frame(t(tempw4$coefficients))     #Store model coefficients as a dataframe in the current list element
      newdf4<-data.frame(same_group=rep(c(0,1),3),dyad.coop.cat=c("ARE_UNFAMILIAR","ARE_UNFAMILIAR","FAMILIAR_1TO5","FAMILIAR_1TO5","FAMILIAR_6PLUS","FAMILIAR_6PLUS"))      #create a new dataset for the purpose of getting predicted values from the REM
      tempdf4<-cbind(newdf4,as.data.frame(predict(tempw4,newdata=newdf4,type="risk",reference="sample")))
      colnames(tempdf4)[ncol(tempdf4)]<-"PRED_VAL"
      pred_list4[[i]]<-tempdf4  #Get predicted values for each of the scenarios contained in the 'newdata' dataframe from the REM. Results returned as relative risks (i.e. exp(raw coef)) and a single sample-wide baseline hazard is used (reference=sample). see ?predict.coxph for more details.
    } else {
      cox_dyad_list_affil[[i]]<-NULL
      pred_list4[[i]]<-NULL
    }
    
    
    
    #Model 5: Associations of non-affiliate dyads
    nonaffil.locs.temp<-which(coop.events$is.affiliate==0 & coop.events$TYPE!="NON-EVENT")
    nonaffil.locs<-c(nonaffil.locs.temp,(nonaffil.locs.temp + 1))
    nonaffil.locs<-sort(nonaffil.locs)
    coop.events.nonaffil<-coop.events[nonaffil.locs,]
    my.surv.coop.nonaffil<-Surv(time = rep(1,dim(coop.events.nonaffil)[1]), event = coop.events.nonaffil$event.indicator)
    
    
    tempw5<-tryCatch(perm.dyad.coop<-coxph(my.surv.coop.nonaffil ~ 
                                           same_group*dyad.coop.cat
                                             + strata(DAY) 
                                             , data = coop.events.nonaffil),warning=function(w) return("W"))
    
    
    if(is.object(tempw5)){        #If the model has been fitted successfully (i.e. without warnings)
      cox_dyad_list_nonaffil[[i]]<-as.data.frame(t(tempw5$coefficients))     #Store model coefficients as a dataframe in the current list element
      newdf5<-data.frame(same_group=rep(c(0,1),3),dyad.coop.cat=c("ARE_UNFAMILIAR","ARE_UNFAMILIAR","FAMILIAR_1TO5","FAMILIAR_1TO5","FAMILIAR_6PLUS","FAMILIAR_6PLUS"))      #create a new dataset for the purpose of getting predicted values from the REM
      tempdf5<-cbind(newdf5,as.data.frame(predict(tempw5,newdata=newdf5,type="risk",reference="sample")))
      colnames(tempdf5)[ncol(tempdf5)]<-"PRED_VAL"
      pred_list5[[i]]<-tempdf5  #Get predicted values for each of the scenarios contained in the 'newdata' dataframe from the REM. Results returned as relative risks (i.e. exp(raw coef)) and a single sample-wide baseline hazard is used (reference=sample). see ?predict.coxph for more details.
    } else {
      cox_dyad_list_nonaffil[[i]]<-NULL
      pred_list5[[i]]<-NULL
    }
    
    
    
    #Model 8: Change in dyads members' common associates over time
    tempw8<-tryCatch(unperm.triad.coop<-coxph(my.surv.coop ~ network.num.coop*(triadic.closure.coop + success.closure) - network.num.coop
                                                + strata(DAY) 
                                                , data = coop.events),warning=function(w) return("W"))
    
    
    if(is.object(tempw8)){                 #If the model has been fitted successfully (i.e. without warnings)
      cox_tri_list[[i]]<-as.data.frame(t(tempw8$coefficients))       #Store model coefficients as a dataframe in the current list element
      time_temp<-as.numeric(coop.events[coop.events$TYPE!="NON-EVENT","TIME"])
      events_temp<-floor(as.numeric(unlist(lapply(split(coop.events,coop.events$DAY),function(x) median(x$network.num.coop)))))
      tt2<-unique(time_temp[which(coop.events[coop.events$TYPE!="NON-EVENT","network.num.coop"] %in% events_temp)])
      day_temp<-floor(tt2/(24*60*60))
      tri_combinations<-expand.grid(day_temp,3,c(0,3))
      newdf8<-data.frame(network.num.coop=rep(events_temp,nrow(tri_combinations)/length(day_temp)),triadic.closure.coop=tri_combinations[,2],success.closure=tri_combinations[,3],DAY=tri_combinations[,1])
      tempdf8<-cbind(newdf8,as.data.frame(predict(tempw8,newdata=newdf8,type="risk",reference="strata")))
      colnames(tempdf8)[ncol(tempdf8)]<-"PRED_VAL"
      pred_list8[[i]]<-tempdf8
    } else {
      cox_tri_list[[i]]<-NULL
      pred_list8[[i]]<-NULL
    }
  
    
  #Calculate success/fail differential from the data from each permuted dataset for use in Figure 3 (see red line and shading).  
  temp_nonevents<-coop.events[coop.events$TYPE=="NON-EVENT",]  #'non-events' = permuted data (i.e., expected rather than observed) 
  perc_store<-c(perc_store,(length(which(temp_nonevents$same_group==1))/nrow(temp_nonevents)))    #proportion of 'non-events' that are successes
  diff.counter<-apply(temp_nonevents,1,function(x) if(x["same_group"]==1){1} else if(x["same_group"]==0){-1})    #label successes as positive, failures as negative 
  daytemp<-floor(temp_nonevents$TIME/(3600*24))
  temp_daydf<-data.frame(EVENT=1:length(diff.counter),sf_diff=diff.counter,Day=daytemp)
  temp_daydf$Day<-temp_daydf$Day-(min(temp_daydf$Day)-1)    #Get Days since day of first interaction
  tempfac<-as.factor(temp_daydf$Day)
  levels(tempfac)<-as.character(1:length(unique(temp_daydf$Day)))
  temp_daydf$Day<-as.numeric(as.character(tempfac))
  day_list<-lapply(split(temp_daydf,temp_daydf$Day),function(x) data.frame(Day=unique(x[,"Day"]),sf_diff=sum(x[,"sf_diff"]),nevents=nrow(x)))  #Get per-day success/fail differential for the ith permuted dataset
  daydf<-do.call(rbind,day_list)
  daydf$csum<-cumsum(daydf$sf_diff)  #Get cumulative sum of per-day success/fail differential for the ith permuted dataset
  perc_store_list[[i]]<-daydf
}

#coop_only<-coop.events[coop.events$TYPE!="NON-EVENT",]
#save(coop_only,file="coop_only.RData")

cox_dyad_df_affil<-do.call(rbind,cox_dyad_list_affil)    #Combine coefficients from each permuted REM for a given model type to get a single dataframe of pREM coefficients (with nrow == nperm)
cox_dyad_df_nonaffil<-do.call(rbind,cox_dyad_list_nonaffil)    #Combine coefficients from each permuted REM for a given model type to get a single dataframe of pREM coefficients (with nrow == nperm)
cox_trt_df<-do.call(rbind,cox_trt_list)
cox_tri_df<-do.call(rbind,cox_tri_list)



#Determine median coefficient values and 95% confidence intervals from quantiles of pREM coefficient distributions:

quant_list3<-apply(cox_trt_df,2,function(x) data.frame(CI_LOW=quantile(x,probs=0.025),MED=quantile(x,probs=0.5),CI_HIGH=quantile(x,probs=0.975),MINIMUM=min(x),MAXIMUM=max(x),I.R.=exp(quantile(x,probs=0.5))))
quant_df3<-do.call(rbind,quant_list3)
#write.csv(quant_df3,"quant_df3.csv")

quant_list4<-apply(cox_dyad_df_affil,2,function(x) data.frame(CI_LOW=quantile(x,probs=0.025),MED=quantile(x,probs=0.5),CI_HIGH=quantile(x,probs=0.975),MINIMUM=min(x),MAXIMUM=max(x),I.R.=exp(quantile(x,probs=0.5))))
quant_df4<-do.call(rbind,quant_list4)
#write.csv(quant_df4,"dyad_quantdf4.csv")

quant_list5<-apply(cox_dyad_df_nonaffil,2,function(x) data.frame(CI_LOW=quantile(x,probs=0.025),MED=quantile(x,probs=0.5),CI_HIGH=quantile(x,probs=0.975),MINIMUM=min(x),MAXIMUM=max(x),I.R.=exp(quantile(x,probs=0.5))))
quant_df5<-do.call(rbind,quant_list5)
#write.csv(quant_df5,"dyad_quantdf5.csv")

quant_list8<-apply(cox_tri_df,2,function(x) data.frame(CI_LOW=quantile(x,probs=0.025),MED=quantile(x,probs=0.5),CI_HIGH=quantile(x,probs=0.975),MINIMUM=min(x),MAXIMUM=max(x),I.R.=exp(quantile(x,probs=0.5))))
quant_df8<-do.call(rbind,quant_list8)
#write.csv(quant_df8,"quant_df8.csv")



#Get dataset of just the observed events, with calculated stats such as dyad.coop.count etc, for use in plotting figures

coop_only<-coop.events[coop.events$TYPE %in% c("COOP_SUCCESS","COOP_FAIL"),]
save(coop_only,file="coop_only.RData")

```




Tests for change in coordination of dyads (duration of events and arrival latencies). The input files for these analyses comprise permuted REM datasets produced by permutation of edge weights or arrival latencies only (Perm 4 - shuffle edge weights only (i.e. without altering the underlying network structure); see Supplementary Fig. 3d) and subsequently processed in Eventnet 0.5.2 


- Model 6: Change in arrival latency (latency between arrival of SOURCE and TARGET preceding an association event) attributable to experimental treatment (same/different treatment class)

```{r}
#To re-run the analysis in the paper, set working directory to: .../Eventnet_output/ptests_perm4_Latency_EventnetOutput

#Note, to run this model a dataframe of REM covariates ('covars', line 331) is required; this is due to an issue with calculating the time-varying covariates 'source.isgroupA' and 'target.isgroupA' using Eventnet. The 'covars' dataset can be accessed from the combined raw data file ('DB_REM_INPUT), as is the case in the MK_permutations.R script (see line 17).

feed_files<-list.files(no..=TRUE) #Get list of files within current directory
coop_indicator<-unlist(sapply(feed_files,function(x) grepl("COOP_EVENTS",x)))
coop_files<-feed_files[coop_indicator]
coef_list6<-list()
pred_list6<-list()

for(i in 1:length(coop_files))  #loop over files within subfolder
{
  print(i)
  coop.events.cdn<-read.csv(coop_files[i],header=T,row.names=NULL)
  coop.events.cdn$DAY<-floor(coop.events.cdn$TIME/(60*60*24))
  temp_groupdf<-covars[covars$TYPE=="IS_GROUP_A",]
  coop.events.cdn$same_group<-apply(coop.events.cdn,1,function(x) if(temp_groupdf[match(x["SOURCE"],temp_groupdf$SOURCE),"WEIGHT"]==temp_groupdf[match(x["TARGET"],temp_groupdf$TARGET),"WEIGHT"]) {1} else {0})  #Check the group assignments of each SOURCE and TARGET pair and create a binary indicator of whether the pair belonged to the same, or different, treatment groups.
  
  #coop.events.cdn$same_group<-apply(coop.events.cdn,1,function(x)  if(as.numeric(x["source.is.groupA"])==as.numeric(x["target.is.groupA"])){1} else {0}) #Check the group assignments of each SOURCE and TARGET pair and create a binary indicator of whether the pair belonged to the same, or different, treatment groups.
  cdn.list<-lapply(split(coop.events.cdn,coop.events.cdn$EVENT_INTERVAL),function(x) if(length(unique(x$EVENT))==2 & length(unique(x$TYPE))==2 & !sum(is.na(x$WEIGHT))){x} else {NULL})
  cdn.final<-do.call(rbind,cdn.list)
  cdn.final$event.indicator<-apply(cdn.final,1,function(x) if(x["TYPE"]=="NON-EVENT"){0} else {1})   #Make sure that events (1) and non-events (0) have separate labels
  my.surv.cdn<-Surv(time = rep(1,dim(cdn.final)[1]), event = cdn.final$event.indicator)  #Create a survival object to serve as the response term in coxph
  
  tempw6<-tryCatch(perm.coord<-coxph(my.surv.cdn ~ 
                                             WEIGHT*same_group 
                                              + strata(DAY) 
                                             , data = cdn.final),warning=function(w) return("W"))
  
  if(is.object(tempw6)){
    coef_list6[[i]]<-as.data.frame(t(tempw6$coefficients))
    newdf6<-data.frame(WEIGHT=rep(1:60,2),same_group=rep(c(0,1),each=60))
    tempdf6<-cbind(newdf6,as.data.frame(predict(tempw6,newdata=newdf6,type="risk",reference="sample")))
    colnames(tempdf6)[ncol(tempdf6)]<-"PRED_VAL"
    pred_list6[[i]]<-tempdf6
  } else {
    coef_list6[[i]]<-NULL
    pred_list6[[i]]<-NULL
  }
}

coop_only_predur<-coop.events.cdn[coop.events.cdn$TYPE!="NON-EVENT",]

coef_df_6<-do.call(rbind,coef_list6)

quant_list6<-apply(coef_df_6[,c("WEIGHT","same_group","WEIGHT:same_group")],2,function(x) data.frame(CI_LOW=quantile(x,probs=0.025),MED=quantile(x,probs=0.5),CI_HIGH=quantile(x,probs=0.975),MINIMUM=min(x),MAXIMUM=max(x),I.R.=exp(quantile(x,probs=0.5))))
quant_df6<-do.call(rbind,quant_list6)
write.csv(quant_df6,"quant_df6.csv")
```


 - Model 7: Change in event duration of dyads attributable to experimental treatment (same/different treatment class)
 

```{r}
#To re-run the analysis in the paper, set working directory to: .../Eventnet_output/ptests_perm4_Duration_EventnetOutput

feed_files<-list.files(no..=TRUE) #Get list of files within current directory
coop_indicator<-unlist(sapply(feed_files,function(x) grepl("COOP_EVENTS",x)))
coop_files<-feed_files[coop_indicator]
coef_list7<-list()
pred_list7<-list()

for(i in 1:length(coop_files))  #loop over files within subfolder
{
  print(i)
  coop.events.cdn<-read.csv(coop_files[i],header=T,row.names=NULL)
  coop.events.cdn$DAY<-floor(coop.events.cdn$TIME/(60*60*24))
  coop.events.cdn$same_group<-apply(coop.events.cdn,1,function(x)  if(as.numeric(x["source.is.groupA"])==as.numeric(x["target.is.groupA"])){1} else {0}) #Check the group assignments of each SOURCE and TARGET pair and create a binary indicator of whether the pair belonged to the same, or different, treatment groups.
  cdn.list<-lapply(split(coop.events.cdn,coop.events.cdn$EVENT_INTERVAL),function(x) if(length(unique(x$EVENT))==2 & length(unique(x$TYPE))==2 & !sum(is.na(x$WEIGHT))){x} else {NULL})
  cdn.final<-do.call(rbind,cdn.list)
  cdn.final$event.indicator<-apply(cdn.final,1,function(x) if(x["TYPE"]=="NON-EVENT"){0} else {1})   #Make sure that events (1) and non-events (0) have separate labels
  my.surv.cdn<-Surv(time = rep(1,dim(cdn.final)[1]), event = cdn.final$event.indicator)  #Create a survival object to serve as the response term in coxph
  
  tempw7<-tryCatch(perm.coord<-coxph(my.surv.cdn ~ 
                                             WEIGHT*same_group
                                              + strata(DAY) 
                                             , data = cdn.final),warning=function(w) return("W"))
  
  if(is.object(tempw7)){
    coef_list7[[i]]<-as.data.frame(t(tempw7$coefficients))
    newdf7<-data.frame(WEIGHT=rep(1:60,2),same_group=rep(c(0,1),each=60))
    tempdf7<-cbind(newdf5,as.data.frame(predict(tempw7,newdata=newdf7,type="risk",reference="sample")))
    colnames(tempdf7)[ncol(tempdf7)]<-"PRED_VAL"
    pred_list7[[i]]<-tempdf7
  } else {
    coef_list7[[i]]<-NULL
    pred_list7[[i]]<-NULL
  }
}

coef_df_7<-do.call(rbind,coef_list7)

quant_list7<-apply(coef_df_7[,c("WEIGHT","same_group","WEIGHT:same_group")],2,function(x) data.frame(CI_LOW=quantile(x,probs=0.025),MED=quantile(x,probs=0.5),CI_HIGH=quantile(x,probs=0.975),MINIMUM=min(x),MAXIMUM=max(x),I.R.=exp(quantile(x,probs=0.5))))
quant_df7<-do.call(rbind,quant_list7)
#write.csv(quant_df7,"quant_df7.csv")
```


Note, Model 8 (change in common associates over time) as presented in the paper is located in the third code chunk (above, see line 230) as it utilizes the same permuted datasets as models 3, 4 and 5. 






Plotting:

Calculation of sample-wide baseline per-dyad and per-individual event rate (per hour) estimates for use in figures. 

```{r}
#load coop_only.RData

coop_only$DYAD<-get_dyad_labels(coop_only)

#Calculate an estimate of baseline rate of association (across whole sample) for all dyad types
coop_only$Hour<-floor(coop_only$TIME/3600)
per_hour<-lapply(split(coop_only,coop_only$Hour),function(x) data.frame(Hour=unique(x[,"Hour"]),num_indivs=length(unique(c(x[,"SOURCE"],x[,"TARGET"]))),num_events=nrow(x),num_dyads=length(unique(x[,"DYAD"]))))
phdf<-do.call(rbind,per_hour)
sum_of_weights<-sum(phdf$num_events)
sum_of_ndyad<-sum(phdf$num_dyads)
weighted_avge_dyad<-sum_of_weights/sum_of_ndyad   #average number of events observed per time period (conditional on individuals having at least one visit during the time period)


#Calculate an estimate of baseline rate of interaction (across whole sample) for just affiliate dyads
coop_only_affil<-coop_only[coop_only$is.affiliate>0,]
coop_only_affil$Hour<-floor(coop_only_affil$TIME/3600)
per_hour_affil<-lapply(split(coop_only_affil,coop_only_affil$Hour),function(x) data.frame(Hour=unique(x[,"Hour"]),num_indivs=length(unique(c(x[,"SOURCE"],x[,"TARGET"]))),num_events=nrow(x),num_dyads=length(unique(x[,"DYAD"]))))
phdf_affil<-do.call(rbind,per_hour_affil)
sum_of_weights_affil<-sum(phdf_affil$num_events)
sum_of_ndyad_affil<-sum(phdf_affil$num_dyads)
weighted_avge_dyad_affil<-sum_of_weights_affil/sum_of_ndyad_affil   #average number of affiliate dyads observed per time period (conditional on dyads being affiliated and having at least one visit during the time period)


#Calculate an estimate of baseline rate of interaction (across whole sample) for just non-affiliate dyads
coop_only_nonaffil<-coop_only[coop_only$is.affiliate==0,]
coop_only_nonaffil$Hour<-floor(coop_only_nonaffil$TIME/3600)
per_hour_nonaffil<-lapply(split(coop_only_nonaffil,coop_only_nonaffil$Hour),function(x) data.frame(Hour=unique(x[,"Hour"]),num_indivs=length(unique(c(x[,"SOURCE"],x[,"TARGET"]))),num_events=nrow(x),num_dyads=length(unique(x[,"DYAD"]))))
phdf_nonaffil<-do.call(rbind,per_hour_nonaffil)
sum_of_weights_nonaffil<-sum(phdf_nonaffil$num_events)
sum_of_ndyad_nonaffil<-sum(phdf_nonaffil$num_dyads)
weighted_avge_dyad_nonaffil<-sum_of_weights_nonaffil/sum_of_ndyad_nonaffil   #average number of affiliate dyads observed per time period (conditional on dyads being affiliated and having at least one visit during the time period)


#Calculate an estimate of baseline rate of interaction (across whole sample) for individuals engaging in successful events
success_only<-coop_only[coop_only$TYPE=="COOP_SUCCESS",]
success_only$hour_success<-floor(success_only$TIME/3600)
success_per_hour<-lapply(split(success_only,success_only$hour_success),function(x) data.frame(Hour=unique(x[,"Hour"]),num_indivs=length(unique(c(x[,"SOURCE"],x[,"TARGET"]))),num_events=nrow(x),num_dyads=length(unique(x[,"DYAD"]))))
phdf_success<-do.call(rbind,success_per_hour)
phdf_success$num_events2<-as.numeric(phdf_success[,"num_events"])*2
sum_of_weights_s<-sum(phdf_success$num_events2)
sum_of_nindiv_s<-sum(phdf_success$num_indivs)
weighted_avge_indiv_s<-sum_of_weights_s/sum_of_nindiv_s   #average number of individuals observed interacting successfully per time period (conditional on individuals having at least one successful event during the time period)

```




Figure 2: The relationship between individual performance and discrimination of task partners.

```{r}
#load Model2__pred_list2.RData

pv_list2<-lapply(pred_list2,function(x) data.frame(t(data.frame(x$PRED_VAL))))
pv_df2<-do.call(rbind,pv_list2)
PI_LOW2<-apply(pv_df2,2,function(x) quantile(x,probs=0.0125))  #Calculate lower bound of 95% prediction interval at each time point
MED_VAL2<-apply(pv_df2,2,function(x) quantile(x,probs=0.5))   #Calculate median predicted value at each time point
PI_HIGH2<-apply(pv_df2,2,function(x) quantile(x,probs=0.9875))  #Calculate upper bound of 95% prediction interval at each time point
plot_df2<-pred_list2[[1]][,c("repeat_fail_deg","repeat_success_deg")]
plot_df2<-cbind(plot_df2,PI_LOW=PI_LOW2,PI_MED=MED_VAL2,PI_HIGH=PI_HIGH2)

plot_df2$PI_LOW<-(plot_df2$PI_LOW*weighted_avge_indiv_s)-weighted_avge_indiv_s  #Convert predictions from relative risk (multipliers) to estimate of increase/decrease in incidence rate relative to sample-wide estimate of baseline incidence rate.
plot_df2$PI_MED<-(plot_df2$PI_MED*weighted_avge_indiv_s)-weighted_avge_indiv_s
plot_df2$PI_HIGH<-(plot_df2$PI_HIGH*weighted_avge_indiv_s)-weighted_avge_indiv_s


indiv_partners<-ggplot(plot_df2,aes(repeat_fail_deg,repeat_success_deg)) + geom_tile(aes(fill=PI_MED)) + scale_fill_gradient(name="success/fail\nrate difference\n(events per hour)\n",low="sky blue",high="dark orange",guide=guide_colourbar(label.position="left")) + scale_x_continuous(breaks=c(0,5,10)) + scale_y_continuous(breaks=c(0,5,10)) + theme_classic() + theme(legend.box.spacing=unit(0,"pt"),legend.margin=margin(c(0.1,1,0.1,0.1)),legend.title.align=0.5,text=element_text(size=7,family="sans"),plot.margin=unit(c(2,8,2,2),"mm")) + xlab("Number of different-class participants with which \n an individual has had multiple associations") + ylab("Number of same-class participants with which \n an individual has had multiple associations") 

#ggsave(filename="indiv_partners_naturespecs240722.png",plot=indiv_partners,type="cairo",dpi=360,width=85,height=65,units="mm")

```





Figure 3: Increase in the ratio of successful to unsuccessful association events as the experiment progressed.

```{r}
#load Fig3__perc_store_list

#Unpermuted success/fail differential over course of experiment
diff.counter<-apply(coop_only,1,function(x) if(x["TYPE"]=="COOP_SUCCESS"){1} else if(x["TYPE"]=="COOP_FAIL"){-1})    #mark successful events as positive, unsuccessful as negative
plot_df_diff<-data.frame(EVENT=1:length(diff.counter),sf_diff=diff.counter,Day=coop_only$DAY[coop_only$TYPE %in% c("COOP_SUCCESS","COOP_FAIL")])
plot_df_diff$Day<-plot_df_diff$Day-(min(plot_df_diff$Day)-1)    #Get Days since day of first interaction
tempfac<-as.factor(plot_df_diff$Day)
levels(tempfac)<-as.character(1:length(unique(plot_df_diff$Day)))
plot_df_diff$Day<-as.numeric(as.character(tempfac))
day_list<-lapply(split(plot_df_diff,plot_df_diff$Day),function(x) data.frame(Day=unique(x[,"Day"]),sf_diff=sum(x[,"sf_diff"]),nevents=nrow(x)))  #get daily success/fail differential
day_df<-do.call(rbind,day_list)
day_df$csum<-cumsum(day_df$sf_diff)  #get cumulative sum of daily success/fail differential

#permuted success/fail differential over course of experiment
#load("~/DB_experiments/Files for publication/Data/perc_store_list.RData")
csum_only<-lapply(perc_store_list,function(x) x$csum)  #extract (only the) cumulative success/fail sums pertaining to each permuted dataset
csum_mat<-do.call(cbind,csum_only)   #Combine all cumulative differentials into a single data structure
PI_LOW<-apply(csum_mat,1,function(x) quantile(x,probs=0.025))   #Calculate lower bound of 95% interval of permuted success/fail differential for each day of the experiment
PI_MED<-apply(csum_mat,1,function(x) quantile(x,probs=0.5))     #Calculate median permuted success/fail differential for each day of the experiment
PI_HIGH<-apply(csum_mat,1,function(x) quantile(x,probs=0.975))   #Calculate upper bound of 95% interval of permuted success/fail differential for each day of the experiment
expected_sf<-data.frame(Day=1:length(PI_LOW),PI_LOW=PI_LOW,PI_MED=PI_MED,PI_HIGH=PI_HIGH)


#data for events per day bar plots (number of successful and unsuccesful events per day)
f_df<-plot_df_diff[which(plot_df_diff$sf_diff==-1),]    #All unsuccessful events
s_df<-plot_df_diff[which(plot_df_diff$sf_diff==1),]      #All successful events
day_lists<-lapply(split(s_df,s_df$Day),function(x) data.frame(Day=unique(x[,"Day"]),nevents_s=nrow(x)))   #Get count of number of successful events per day
day_listf<-lapply(split(f_df,f_df$Day),function(x) data.frame(Day=unique(x[,"Day"]),nevents_f=nrow(x)))  #Get count of number of unsuccessful events per day
dfs<-do.call(rbind,day_lists)
dff<-do.call(rbind,day_listf)
dfs2<-data.frame(Day=c(1,2,3,4,5,8,10,11,12,13,15,25),nevents_s=c(0,0,0,0,0,0,0,0,0,0,0,0))#replace missing values with zeros (i.e. days without successful events)
dfs_fin<-rbind(dfs2,dfs)
dff2<-data.frame(Day=c(9,14,19,21),nevents_f=c(0,0,0,0))  #replace missing values with zeros (i.e. days without unsuccessful events)
dff_fin<-rbind(dff,dff2)
day_df2<-merge(day_df,dfs_fin,by="Day")
day_df3<-merge(day_df2,dff_fin,by="Day")   
day_df3$nevents_f<-day_df3$nevents_f*-1   #Convert counts of unsuccessful events from negative to positive (sign needs to be removed for plotting)

day_df$COL<-rep("observed",nrow(day_df))
expected_sf$COL<-rep("permuted",nrow(expected_sf))

#Colour plot of trends in successful/unsuccessful events over the period of the experiment
timeplot_trends_colour<-ggplot() + geom_col(data=day_df3,aes(Day,nevents_s),fill="white",colour="gray50") + geom_col(data=day_df3,aes(Day,nevents_f),fill="white",colour="gray50") + geom_hline(yintercept=0) + geom_line(data=expected_sf,aes(Day,PI_MED,colour=COL),lwd=0.5) + geom_ribbon(data=expected_sf,aes(x=Day,ymin=PI_LOW,ymax=PI_HIGH),fill="red",alpha=0.25) + geom_line(data=day_df,aes(Day,csum,colour=COL),lwd=1) + theme_classic() + ylab("Success/Fail differential") + xlab("Days since beginning of experiment") + theme(legend.position=c(0.1,1),legend.justification=c(0.2,1.2),legend.margin=margin(c(0.1,0.1,0.1,0.1)),legend.title=element_blank(),axis.text=element_text(size=7,family="sans"),axis.title=element_text(size=7,family="sans"),legend.text=element_text(size=7,family="sans")) + scale_colour_manual("",values=c("observed"="black","permuted"="red"))

#ggsave(filename="timeplot_trends_colour_naturespecs.pdf",plot=timeplot_trends_colour,width=88,height=50,units="mm")
```





Figure 4: Assortment by treatment class as dyads gained experience of the task.

```{r}
#load model4__pred_list4.RData
#load model5__pred_list5.RData

#affiliates
pv_list4<-lapply(pred_list4,function(x) data.frame(t(data.frame(x$PRED_VAL))))
pv_df4<-do.call(rbind,pv_list4)
PI_LOW4<-apply(pv_df4,2,function(x) quantile(x,probs=0.025))   #Get lower bounds of 95% prediction intervals (for different categories of prior experience)
MED_VAL4<-apply(pv_df4,2,function(x) quantile(x,probs=0.5))     #Get median predicted values (for different categories of prior experience)
PI_HIGH4<-apply(pv_df4,2,function(x) quantile(x,probs=0.975))   #Get upper bounds of 95% prediction intervals (for different categories of prior experience)
plot_df4<-pred_list4[[1]][,c("same_group","dyad.coop.cat")]
plot_df4<-cbind(plot_df4,PI_LOW=PI_LOW4,MED_VAL=MED_VAL4,PI_HIGH=PI_HIGH4)
plot_df4$PI_LOW<-plot_df4$PI_LOW*weighted_avge_dyad_affil  #Convert predictions from relative risk (multipliers) to estimate of increase/decrease in incidence rate relative to sample-wide estimate of baseline incidence rate.
plot_df4$MED_VAL<-plot_df4$MED_VAL*weighted_avge_dyad_affil
plot_df4$PI_HIGH<-plot_df4$PI_HIGH*weighted_avge_dyad_affil

plot_df4$dyad.coop.cat<-apply(plot_df4,1,function(x) if(x["dyad.coop.cat"]=="ARE_UNFAMILIAR"){"0"} else if(x["dyad.coop.cat"]=="FAMILIAR_1TO5") {"1-5"} else if(x["dyad.coop.cat"]=="FAMILIAR_6PLUS"){"6+"})


#non-affiliates
pv_list5<-lapply(pred_list5,function(x) data.frame(t(data.frame(x$PRED_VAL))))
pv_df5<-do.call(rbind,pv_list5)
PI_LOW5<-apply(pv_df5,2,function(x) quantile(x,probs=0.025))
MED_VAL5<-apply(pv_df5,2,function(x) quantile(x,probs=0.5))
PI_HIGH5<-apply(pv_df5,2,function(x) quantile(x,probs=0.975))
plot_df5<-pred_list5[[1]][,c("same_group","dyad.coop.cat")]
plot_df5<-cbind(plot_df5,PI_LOW=PI_LOW5,MED_VAL=MED_VAL5,PI_HIGH=PI_HIGH5)
plot_df5$PI_LOW<-plot_df5$PI_LOW*weighted_avge_dyad_nonaffil
plot_df5$MED_VAL<-plot_df5$MED_VAL*weighted_avge_dyad_nonaffil
plot_df5$PI_HIGH<-plot_df5$PI_HIGH*weighted_avge_dyad_nonaffil
plot_df5$dyad.coop.cat<-apply(plot_df5,1,function(x) if(x["dyad.coop.cat"]=="ARE_UNFAMILIAR"){"0"} else if(x["dyad.coop.cat"]=="FAMILIAR_1TO5") {"1-5"} else if(x["dyad.coop.cat"]=="FAMILIAR_6PLUS"){"6+"})


#Note, the following ggplot code for plotting affiliate and non-affiliate data is the same. Un-comment the relevant lines (sdf & fdf) below to choose whether to plot affiliate or non-affiliate predictions:

#sdf<-plot_df4[plot_df4$same_group==1,]  #for plotting affiliates
#fdf<-plot_df4[plot_df4$same_group==0,]  #for plotting affiliates
#reference_line_value<-weighted_avge_dyad_affil  #for plotting affiliates

sdf<-plot_df5[plot_df5$same_group==1,]   #for plotting non-affiliates
fdf<-plot_df5[plot_df5$same_group==0,]   #for plotting non-affiliates
reference_line_value<-weighted_avge_dyad_nonaffil  #for plotting non-affiliates

sdf$Type<-rep("same-class ",nrow(sdf))
fdf$Type<-rep("different-class ",nrow(fdf))

#Plot in colour
dyads_colour<-ggplot() + geom_linerange(data=fdf,aes(x=dyad.coop.cat,ymin=PI_LOW,ymax=PI_HIGH,colour=Type),position=position_nudge(-0.05,0),size=1) + geom_linerange(data=sdf,aes(x=dyad.coop.cat,ymin=PI_LOW,ymax=PI_HIGH,colour=Type),position=position_nudge(0.05,0),size=1) + geom_point(data=fdf,aes(x=dyad.coop.cat,y=MED_VAL),colour="navy blue",position=position_nudge(-0.05,0),size=1.5,shape=21,fill="sky blue") + geom_point(data=sdf,aes(x=dyad.coop.cat,y=MED_VAL),colour="darkorange4",position=position_nudge(0.05,0),size=1.5,shape=21,fill="dark orange") + theme_classic() + xlab("Number of previous associations between members of a dyad") + ylab("Expected association rate (events per hour)") + geom_hline(yintercept=reference_line_value,lty=2) + labs(title="Non-affiliates") + theme(plot.title=element_text(size=7,family="sans",hjust=0.5,face="bold"),axis.text=element_text(size=7,family="sans"),axis.title=element_text(size=7,family="sans"),legend.text=element_text(size=7,family="sans"),legend.position=c(0.1,1),legend.justification=c(0.2,1.2),legend.background=element_blank(),legend.margin=margin(c(0.1,0.1,0.1,0.1)),legend.title=element_blank(),legend.box.background=element_rect(colour="black"),legend.box.margin=margin(c(0.1,0.1,0.1,0.1))) + scale_colour_manual("",values=c("same-class "="dark orange","different-class "="sky blue"))

#ggsave(filename="nonaffil_dyads_colour_naturespecs020423.pdf",plot=dyads_colour,width=88,height=60,units="mm")
```



Figure 5: Change in quantity and activity of different dyad types as the experiment progressed. Requires a dataset containing only observed events ('coop_only.RData) to run.

```{r}

#Initialization of vectors/variables for use in loop
affil_same_event_store<-c()
affil_diff_event_store<-c()
naffil_same_event_store<-c()
naffil_diff_event_store<-c()
affil_same_dyad_store<-c()
affil_diff_dyad_store<-c()
naffil_same_dyad_store<-c()
naffil_diff_dyad_store<-c()
affil_same_event_counter<-0
affil_diff_event_counter<-0
naffil_same_event_counter<-0
naffil_diff_event_counter<-0
affil_same_dyad_counter<-0
affil_diff_dyad_counter<-0
naffil_same_dyad_counter<-0
naffil_diff_dyad_counter<-0


for(i in 1:nrow(coop_only)){      #for each association event...
  
  #cumulative counts of number of events between same-class affiliates and number of this type of dyad
  if(coop_only[i,"is.affiliate"]>0 && coop_only[i,"same_group"]==1) {
    affil_same_event_counter<-affil_same_event_counter+1
    if(coop_only[i,"dyad.coop.count"]==0){
      affil_same_dyad_counter<-affil_same_dyad_counter+1
    }
    
  #cumulative counts of number of events between different-class affiliates and number of this type of dyad
  }
  if(coop_only[i,"is.affiliate"]>0 && coop_only[i,"same_group"]==0) {
    affil_diff_event_counter<-affil_diff_event_counter+1
    if(coop_only[i,"dyad.coop.count"]==0){
      affil_diff_dyad_counter<-affil_diff_dyad_counter+1
    }
  }
  
  #cumulative counts of number of events between same-class non-affiliates and number of this type of dyad
  if(coop_only[i,"is.affiliate"]==0 && coop_only[i,"same_group"]==1) {
    naffil_same_event_counter<-naffil_same_event_counter+1
    if(coop_only[i,"dyad.coop.count"]==0){
      naffil_same_dyad_counter<-naffil_same_dyad_counter+1
    }
  }
  
  #cumulative counts of number of events between different-class non-affiliates and number of this type of dyad
  if(coop_only[i,"is.affiliate"]==0 && coop_only[i,"same_group"]==0) {
    naffil_diff_event_counter<-naffil_diff_event_counter+1
    if(coop_only[i,"dyad.coop.count"]==0){
      naffil_diff_dyad_counter<-naffil_diff_dyad_counter+1
    }
  }
  
  #store cumulative counts
  affil_same_event_store<-c(affil_same_event_store,affil_same_event_counter)
  affil_diff_event_store<-c(affil_diff_event_store,affil_diff_event_counter)
  naffil_same_event_store<-c(naffil_same_event_store,naffil_same_event_counter)
  naffil_diff_event_store<-c(naffil_diff_event_store,naffil_diff_event_counter)
  affil_same_dyad_store<-c(affil_same_dyad_store,affil_same_dyad_counter)
  affil_diff_dyad_store<-c(affil_diff_dyad_store,affil_diff_dyad_counter)
  naffil_same_dyad_store<-c(naffil_same_dyad_store,naffil_same_dyad_counter)
  naffil_diff_dyad_store<-c(naffil_diff_dyad_store,naffil_diff_dyad_counter)
  
}

as_rate<-affil_same_event_store/affil_same_dyad_store   #Instantaneous number of events per dyad for same-class affiliates
adf_rate<-affil_diff_event_store/affil_diff_dyad_store  #Instantaneous number of events per dyad for different-class affiliates
nas_rate<-naffil_same_event_store/naffil_same_dyad_store #Instantaneous number of events per dyad for same-class non-affiliates
nadf_rate<-naffil_diff_event_store/naffil_diff_dyad_store  #Instantaneous number of events per dyad for different-class non-affiliates
plot_df<-data.frame(EVENT=1:3117,as_rate,adf_rate,nas_rate,nadf_rate,AS_DYADS=affil_same_dyad_store,ADF_DYADS=affil_diff_dyad_store,NAS_DYADS=naffil_same_dyad_store,NADF_DYADS=naffil_diff_dyad_store)

plot_df$A_DYADS_TOT<-plot_df$AS_DYADS + plot_df$ADF_DYADS  #cumulative count of total number of affiliated dyads
plot_df$NA_DYADS_TOT<-plot_df$NAS_DYADS + plot_df$NADF_DYADS   #cumulative count of total number of non-affiliated dyads
plot_df$NA_DYADS_TOT<-plot_df$NA_DYADS_TOT/100   #transformation required for scaling of secondary plotting axis
plot_df$NAS_DYADS<-plot_df$NAS_DYADS/100     #transformation required for scaling of secondary plotting axis

plot_df_sc<-plot_df[,c("EVENT","as_rate","nas_rate")]
plot_df_sc$Type<-rep("same-class",nrow(plot_df))

plot_df_dc<-plot_df[,c("EVENT","adf_rate","nadf_rate")]
plot_df_dc$Type<-rep("different-class",nrow(plot_df))

#plot events per dyad (and dyad numbers) for affiliated dyads
affil_dyadrates<-ggplot() + geom_col(data=plot_df,aes(EVENT,A_DYADS_TOT),colour="gray90") + geom_col(data=plot_df,aes(EVENT,AS_DYADS),colour="gray70") + geom_line(data=plot_df_sc,aes(EVENT,as_rate,colour=Type)) + geom_line(data=plot_df_dc,aes(EVENT,adf_rate,colour=Type)) + labs(title="Affiliates") + theme_classic() + theme(plot.title=element_text(size=7,family="sans",hjust=0.5,face="bold"),text=element_text(size=7,family="sans"),legend.position=c(0.1,1),legend.justification=c(0.2,1.2),legend.background=element_blank(),legend.margin=margin(c(0.1,0.1,0.1,0.1)),legend.title=element_blank(),legend.box.background=element_rect(colour="black"),legend.box.margin=margin(c(0.1,0.1,0.1,0.1))) + xlab("Number of association events since \n beginning of experiment") + ylab("Mean number of association \n events per dyad") + scale_y_continuous(sec.axis=sec_axis(trans=~.*1,name="Dyad count")) + scale_colour_manual("",values=c("same-class"="dark orange","different-class"="sky blue"))

#ggsave(filename="affil_dyadrates020423.png",plot=affil_dyadrates,type="cairo",dpi=360,width=85,height=55,units="mm")

#plot events per dyad (and dyad numbers) for non-affiliated dyads
naffil_dyadrates<-ggplot() + geom_col(data=plot_df,aes(EVENT,NA_DYADS_TOT),colour="gray90") + geom_col(data=plot_df,aes(EVENT,NAS_DYADS),colour="gray70") + geom_line(data=plot_df_sc,aes(EVENT,nas_rate,colour=Type)) + geom_line(data=plot_df_dc,aes(EVENT,nadf_rate,colour=Type)) + theme_classic() + scale_y_continuous(sec.axis=sec_axis(trans=~.*100,name="Dyad count")) + labs(title="Non-affiliates") + theme(plot.title=element_text(size=7,family="sans",hjust=0.5,face="bold"),text=element_text(size=7,family="sans"),legend.position=c(0.1,1),legend.justification=c(0.2,1.2),legend.background=element_blank(),legend.margin=margin(c(0.1,0.1,0.1,0.1)),legend.title=element_blank(),legend.box.background=element_rect(colour="black"),legend.box.margin=margin(c(0.1,0.1,0.1,0.1))) + xlab("Number of association events since \n beginning of experiment") + ylab("Mean number of association \n events per dyad") + scale_colour_manual("",values=c("same-class"="dark orange","different-class"="sky blue"))

#ggsave(filename="naffil_dyadrates020423.png",plot=naffil_dyadrates,type="cairo",dpi=360,width=85,height=55,units="mm")
```





Figure 6: Convergence in the social neighbourhoods of compatible task participants over the duration of the experiment.

```{r}
#load Model8__pred_list8.RData

pv_list8_temp1<-lapply(pred_list8,function(x) cbind(x,PRED_VAL2=x$PRED_VAL*weighted_avge_dyad))  #Transform predicted values from relative risk (multiplier) to increase/decrease in number of events per unit time relative to sample-wide baseline.
pv_list8<-lapply(pv_list8_temp1,function(x) data.frame(t(data.frame(x$PRED_VAL2))))
pv_df8<-do.call(rbind,pv_list8)
PI_LOW8<-apply(pv_df8,2,function(x) quantile(x,probs=0.025))  #Calculate lower bound of 95% prediction interval at each time point
MED_VAL8<-apply(pv_df8,2,function(x) quantile(x,probs=0.5))   #Calculate median predicted value at each time point
PI_HIGH8<-apply(pv_df8,2,function(x) quantile(x,probs=0.975))  #Calculate upper bound of 95% prediction interval at each time point
plot_df8<-pv_list8_temp1[[1]][,c("network.num.coop","DAY","success.closure")]
plot_df8<-cbind(plot_df8,PI_LOW=PI_LOW8,MED_VAL=MED_VAL8,PI_HIGH=PI_HIGH8)
plot_df8$DAY<-plot_df8$DAY-(min(plot_df8$DAY)-1)    #Get Days since day of first interaction
tempfac<-as.factor(plot_df8$DAY)
levels(tempfac)<-as.character(1:length(unique(plot_df8$DAY)))
plot_df8$DAY<-as.numeric(as.character(tempfac))

plot_df_s0<-plot_df8[plot_df8$success.closure==0,]
plot_df_s10<-plot_df8[plot_df8$success.closure==3,]

plot_df_s0$Type<-rep("mixed-class triads",nrow(plot_df_s0))
plot_df_s10$Type<-rep("same-class triads",nrow(plot_df_s10))

closure_plot<-ggplot() + geom_line(data=plot_df_s10,aes(DAY,MED_VAL,colour=Type),lwd=1) + geom_ribbon(data=plot_df_s10,aes(x=DAY,ymin=PI_LOW,ymax=PI_HIGH),fill="#800080ff",alpha=0.2) + geom_line(data=plot_df_s0,aes(DAY,MED_VAL,colour=Type),lwd=1) + geom_ribbon(data=plot_df_s0,aes(x=DAY,ymin=PI_LOW,ymax=PI_HIGH),fill="#4d4d4dff",alpha=0.2) + theme_classic() + xlab("Days since beginning of experiment") + ylab("Predicted association rate \n (events per hour)") + theme(text=element_text(size=7,family="sans"),legend.direction="horizontal",legend.position=c(0.5,1)) + scale_colour_manual(name=element_blank(),values=c("same-class triads"="#800080ff","mixed-class triads"="#4d4d4dff"))

#ggsave(filename="closure_020423.pdf",plot=closure_plot,width=65,height=50,units="mm")
```



Supplementary Fig. 1: Distribution of overall task experience amongst individuals and dyads. Requires a dataset containing only observed events ('coop_only.RData) to run.

```{r}

source_num_events<-with(coop_only,tapply(IS_OBSERVED,SOURCE,sum)) #calculate number of events each observed individual participated in as the SOURCE
target_num_events<-with(coop_only,tapply(IS_OBSERVED,TARGET,sum)) #calculate number of events each observed individual participated in as the TARGET
all_num_events<-data.frame(ID=c(names(source_num_events),names(target_num_events)),NUM_EVENTS=c(source_num_events,target_num_events))
all_num_events<-na.omit(all_num_events)
allexp<-as.data.frame(with(all_num_events,tapply(NUM_EVENTS,ID,sum))) #calculate overall number of events per individual (as either SOURCE or TARGET)
colnames(allexp)<-"NUM_EVENTS"

exp_store<-c()
for(i in 1:50){exp_store<-c(exp_store,sum(allexp$NUM_EVENTS>i))}   #Calculate the number of individuals that participated in more than i (where i ranges from 1 to 50) association events.
plot_df<-data.frame(NUM_EVENTS=1:50,NUM_INDIVS=exp_store)

#Plot number of individuals that participated in greater than a given number of association events
exp_indivs<-ggplot(aes(NUM_EVENTS,NUM_INDIVS),data=plot_df) + geom_line() + theme_classic() + xlab("Threshold number of association events") + ylab("Number of individuals") + ylim(0,150) + geom_vline(xintercept=3,linetype="dashed") + geom_vline(xintercept=21,linetype="dotted") + theme(plot.title=element_text(size=7,family="sans",hjust=0.5,face="bold"),axis.text=element_text(size=7,family="sans"),axis.title=element_text(size=7,family="sans")) + labs(title="Individuals")

#ggsave(filename="exp_indivs_280822.png",plot=exp_indivs,type="cairo",dpi=360,width=60,height=50,units="mm")

exp.list.dyad<-lapply(split(coop_only,coop_only$DYAD),function(x) if(nrow(x)) {data.frame(DYAD=unique(x$DYAD),NUM_EVENTS=max(x$dyad.coop.count),IS_AFFIL=max(x$is.affiliate),SAME_GROUP=unique(x$same_group))})  #For each dyad, get total sample-wide number of association events along with dyad characteristics (affiliation, class combination)
exp_df.dyad<-do.call(rbind,exp.list.dyad)
exp_df.dyad$NUM_EVENTS<-exp_df.dyad$NUM_EVENTS+1

exp_store.affildyad<-c()
exp_store.nonaffildyad<-c()
for(i in 1:50){
  exp_store.affildyad<-c(exp_store.affildyad,sum(exp_df.dyad[exp_df.dyad$IS_AFFIL==1,"NUM_EVENTS"]>i))   #Calculate how many affiliate dyads participated in greater than a given number (i) of association events
  exp_store.nonaffildyad<-c(exp_store.nonaffildyad,sum(exp_df.dyad[exp_df.dyad$IS_AFFIL==0,"NUM_EVENTS"]>i)) #Calculate how many non-affiliate dyads participated in greater than a given number (i) of association events
}
plot_df.affildyad<-data.frame(NUM_EVENTS=1:50,NUM_DYADS=exp_store.affildyad)
plot_df.nonaffildyad<-data.frame(NUM_EVENTS=1:50,NUM_DYADS=exp_store.nonaffildyad)

#Plot number of affiliate dyads that participated in greater than a given number of association events
exp_dyads_affil<-ggplot(aes(NUM_EVENTS,NUM_DYADS),data=plot_df.affildyad) + geom_line() + theme_classic() + xlab("Threshold number of association events") + ylab("Number of affiliated dyads") +  theme(plot.title=element_text(size=7,family="sans",hjust=0.5,face="bold"),axis.text=element_text(size=7,family="sans"),axis.title=element_text(size=7,family="sans")) + ylim(0,20) + labs(title="Affiliates")

#ggsave(filename="exp_affildyads_280822.png",plot=exp_dyads_affil,type="cairo",dpi=360,width=60,height=50,units="mm")

#Plot number of non-affiliate dyads that participated in greater than a given number of association events
exp_dyads_nonaffil<-ggplot(aes(NUM_EVENTS,NUM_DYADS),data=plot_df.nonaffildyad) + geom_line() + theme_classic() + xlab("Threshold number of association events") + ylab("Number of unaffiliated dyads") + geom_vline(xintercept=4,linetype="dashed") + geom_vline(xintercept=9,linetype="dotted") + theme(plot.title=element_text(size=7,family="sans",hjust=0.5,face="bold"),axis.text=element_text(size=7,family="sans"),axis.title=element_text(size=7,family="sans")) + labs(title="Non-affiliates")

#ggsave(filename="exp_nonaffildyads_280822.png",plot=exp_dyads_nonaffil,type="cairo",dpi=360,width=60,height=50,units="mm")

```

