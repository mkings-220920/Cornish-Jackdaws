---
title: "Darwin Board experiment - cleaning & processing of raw RFID data annotated/markdown"
author: "MK"
date: "18 November 2019"
output: word_document
---

Load required packages and functions

```{r}
setwd("C:\\Users\\Mike\\Documents\\DB_experiments\\Files for publication\\Scripts")
source("coop_time.R")              #Get the time at which the experiment started from the datafile header
source("check_arrdep.R")           #Check that the frequencies of ARRIVAL and DEPARTURE labels match
source("fix_labelfreq.R")          #Fix missing departure labels in RFID datastream
source("depdisp_fill.R")           #(Sub-function called by fix_labelfreq) Fill in missing DEPARTURE and REPLACEMENT event labels
source("concat5.R")                #Concatenate neighbouring cooperation event labels
source("check_labelfreq.R")        #Calculate the frequencies of each type of event label and check 
source("solo_precoop2.R")          #Get SOLO and PRE-COOP events in Eventnet format
source("coop_postcoop2.R")         #Get COOP and POST-COOP events in Eventnet format
source("backfill_doors2.R")        #Calculate the door states of the task during each event
source("filt_pre_post4.R")         #Remove duplicate PRE and POST-COOP events
source("get_scrounge2.R")          #Identify and label SCROUNGE events
source("concat_soloprepost.R")     #Concatenate PRE and POST-COOP events with neighbouring SOLO events
source("concat_onlysolo.R")        #Concatenate SOLO events (only with other SOLO events)
```


Loop through each raw RFID file. The following clean-up procedures are performed: 

```{r}
#set working directory to folder containing RFID data files.
feed_dir<-"C:\\Users\\Mike\\Documents\\DB_experiments\\Initial submission\\Github\\Data"
setwd(feed_dir)  #set working directory

feed_files<-list.files(no..=TRUE) #Get list of files within current directory
out_list<-list()
checklist<-list()

for(j in 1:length(feed_files))  #loop over each file within subfolder
{
  f_name<-paste(feed_dir,toString(feed_files[j]),sep="\\")   #append current file name to directory name to get complete path
  tag<-paste(substr(f_name,1,(nchar(f_name)-4)),".csv",sep="") #add .csv to the end of the path
  print(f_name)                               #print current filename
  df<-read.csv(tag,header=T,row.names=NULL)  #open csv file pointed to by the path and store as a data frame.
  if(!is.null(dim(df)) & nrow(df)>1)   #sanity check required to make sure that the current dataframe exists and is not empty
  { 
    #Get time of Start of Experiment
    st_temp<-substr(colnames(df)[1],2,nchar(colnames(df)[1]))  #Get start time (string)
    st_list<-coop_time(st_temp)                           #Get time of START_EXPERIMENT
    st_time<-st_list$secs                             #Store start time (numeric)
    
    #Fix leading zeros (that have been removed by Excel) and add a unique event identifier
    df[,3]<-apply(df,1,function(x) if(substr(toString(x[3]),1,1)=="0"){x[3]} else {paste("0",toString(x[3]),sep="")})  #Fix leading zeros (that have been removed by Excel)
    df<-cbind(df,pos=1:nrow(df))   #add a unique identifier for each entry
    
     #Add column that gives time in seconds from the start of the experiment
    t_list<-apply(df,1,function(a) coop_time(a))              #add a column that gives time in seconds
    df$secs<-as.numeric(unlist(lapply(t_list,function(x) x$secs)))       #add a column that gives time in seconds
    
    #Find and correct missing DEPARTURE labels
    check_adlist<-check_arrdep(df)     #Check arrivals/departures
    if(length(check_adlist$alocs) || length(check_adlist$blocs)){
      df2<-fix_labelfreq(df,check_adlist)              #Fix missing (departure) labels
    } else {df2<-df}
  
    df2<-df2[order(df2[,"secs"],df2[,"pos"]),]     #order the dataframe by time and entry identifier
    
    #Concatenate duplicate cooperation events
    if(!is.null(df2)){                 #If there are events in the current data file
      if(length(which(df2[,2] %in% c("STARTCOOP_SUCCESS","STARTCOOP_FAIL")))){      #If there are cooperation events in the current data file  
        df2<-concat5(df2)                 #concatenate duplicate cooperation labels
        print("CONCATENATION")                               
      }
    }
    
     #Add Site designation
    if(length(grep("STSTR",f_name))){                 #Check filename to determine Site/Feeder
      df2$SITE<-rep("STREAM",nrow(df2))    #add site designation (STREAM)
    } else if(length(grep("STEDY",f_name))){          #Check filename to determine Site/Feeder
      df2$SITE<-rep("EDDY",nrow(df2))      #add site designation (EDDY)
    }
    
    checklist[[j]]<-check_labelfreq(df2)   #Check the frequencies of all label type (i.e. number of Arrivals should equal number of Departures. Run final checks on balance of label frequencies and output in checklist
    spclist<-solo_precoop2(df2)    #get solo and pre-coop events in REM format
    cpclist<-coop_postcoop2(df2)   #get coop and post-coop events in REM format
    repmnts<-apply(df2[which(df2[,2]=="REPLACEMENT"),],1,function(a) data.frame(SOURCE=unlist(strsplit(toString(a["ID"]),"_"))[2],TARGET=unlist(strsplit(toString(a["ID"]),"_"))[1],TIME=a["secs"],TYPE="REPLACEMENT",WEIGHT=0,SITE=a["SITE"],ANTENNA=NA))             #get replacements in REM format
    repmnts_df<-do.call(rbind,repmnts)
    allREM<-rbind(spclist[[1]],spclist[[2]],cpclist[[1]],cpclist[[2]],cpclist[[3]],cpclist[[4]],repmnts_df)   #Combine all event types into single REM dataframe
    if(!is.null(allREM)){
      allREM<-backfill_doors2(allREM,st_time)      #back-fill info regarding what door-state the task is in at the time each event occurred
      if(nrow(allREM[allREM[,"TYPE"] %in% c("COOP_SUCCESS","COOP_FAIL"),])){     #If cooperation events have occurred
        allREM<-get_scrounge2(allREM)                     #Find scrounging events
        allREM<-allREM[order(allREM$TIME),]                   
        allREM3<-filt_pre_post4(allREM)                     #Remove incorrectly assigned pre and post-coop event labels
        allREM3<-allREM3[order(allREM3[,"TIME"]),]
        allREM3<-allREM3[,c("SOURCE","TARGET","TIME","TYPE","WEIGHT","SITE","lock_bool","high_bool","low_bool","ANTENNA")]
        allREM4<-concat_soloprepost(allREM3)          #concatenate duplicate pre and post-coop labels
        allREM5<-concat_onlysolo(allREM4)             #concatenate duplicate solo event labels
        out_list[[j]]<-allREM5
      } else {
        allREM5<-concat_onlysolo(allREM)
        out_list[[j]]<-allREM5 
      }
    } else {
      out_list[[j]]<-NULL
    }
  } else {
    out_list[[j]]<-NULL
    checklist[[j]]<-NULL
  }
}
#checkdf<-do.call(rbind,checklist)
#write.csv(checkdf,file="checkdf.csv")
outfin<-do.call(rbind,out_list)
```


Filter out erroneous RFID codes (codes that are too long or short to be identifiable, such as arise when the data logger battery is failing)

```{r}
#Check SOURCE and TARGET RFID codes for errors and filter them out
outfin<-outfin[order(outfin[,"TIME"]),]
source_nchar<-apply(outfin,1,function(x) nchar(as.character(x["SOURCE"])))   #Get the number of characters in the RFID code of each SOURCE
target_nchar<-apply(outfin,1,function(x) nchar(as.character(x["TARGET"])))  #Get the number of characters in the RFID code of each TARGET
wrong_df<-outfin[which(source_nchar!=8 | target_nchar!=8),]                           #Get the RFID codes that are too long or short to be valid
#write.csv(wrong_df,"wrong_df201119.csv")
correct_df<-outfin[which(source_nchar==8 & target_nchar==8),]     #Get the valid RFID codes that can be used to look up jackdaw IDs in the database
outfin<-correct_df              
```

Convert the remaining, valid RFID codes to unique jackdaw IDs (required as some of the birds are re-ringed during the breeding season)

```{r}
setwd("C:\\Users\\Mike\\Documents\\DB_experiments")
lh_df<-read.csv("LH140120.csv",header=T)                           #Read in Life History info dataframe
lh_df<-lh_df[order(as.numeric(as.POSIXct(lh_df$DATE,format="%d/%m/%Y"))),]

#RFID-to-ID reference
rfid_temp<-lh_df[which(lh_df[,"ID"] %in% group_df[,"SOURCE"]),c("ID","RFID")]    #Filter the LH dataframe to get a dataframe just containing the RFID codes and unique Jackdaw ID of each individual that was assigneda treatment group in the experiment
rfid_temp<-rfid_temp[rfid_temp[,"RFID"]!="",]    #Remove LH dataframe entries pertaining to periods prior to when an RFID ring was fitted
rfid_temp<-rfid_temp[!duplicated(rfid_temp),]       #Remove duplicate rows
rfid_temp$mod_tag<-apply(rfid_temp,1,function(x) paste(substr(x["RFID"],1,2),tolower(substr(x["RFID"],7,10)),"00",sep=""))   #Convert RFID code from original, uncondensed format to the shortened 8-char format used by the Darwin Board
rfid_fin<-rfid_temp[,c("ID","mod_tag")]   #RFID reference dataframe that contains unique jackdaw IDs and corresponding RFID codes in Darwin Board format 
#write.csv(rfid_fin,"rfidfin_raw140120.csv")

#Manually check and correct the rfid_fin dataframe
indivs<-unique(c(as.character(outfin$SOURCE),as.character(outfin$TARGET)))
missing<-indivs[which(!indivs %in% rfid_fin[,"mod_tag"])]
#write.csv(missing,"missing140120.csv")

#Note, some of the individuals marked as missing are missing because they were not assigned a treatment group, not because their RFID code is invalid, so putting these missing cases back in actually puts the individuals that didn't have treatment assignments back in. These then have to be removed again (done at the end, see later section). Inefficient, can be improved.

#rfid_fin<-read.csv("rfid_fin211119.csv",header=T)
missing_corr<-read.csv("missing_corrected_140120.csv",header=T)    
rfid_fin<-rbind(rfid_fin,missing_corr)
rfid_fin<-rfid_fin[!duplicated(rfid_fin),]  #Final RFID reference dataframe that contains unique jackdaw IDs and corresponding RFID codes in Darwin Board format 
#rfid_fin<-read.csv("rfid_fin211119.csv",header=T)

#remove interactions featuring the tag "0104d700" - this tag code was duplicated after a re-ringing and consequently the ID of the jackdaw cannot be accurately identified
outfin<-outfin[which(outfin$SOURCE!="0104d700"),]
outfin<-outfin[which(outfin$TARGET!="0104d700"),]

#merge the processed datastream with the RFID reference dataframe to get SOURCE and TARGET as unique jackdaw ID codes rather than RFID codes
outfin2<-merge(outfin,rfid_fin,by.x="SOURCE",by.y="mod_tag")
outfin2<-merge(outfin2,rfid_fin,by.x="TARGET",by.y="mod_tag")
outfin2$SOURCE<-outfin2$ID.x
outfin2$TARGET<-outfin2$ID.y
outfin3<-outfin2[,c("SOURCE","TARGET","TIME","TYPE","WEIGHT","SITE","lock_bool","high_bool","low_bool","ANTENNA")]
outfin3<-outfin3[order(outfin3[,"TIME"]),]
outfin4<-outfin3[!duplicated(outfin3),]
#write.csv(outfin4,file="outfin4_211119.csv")
```


Prepare the desired REM covariates (At which times each individual could have been observed ('risk set'), Treatment group, Parent-Offspring relations, Sibling relations, breeding partner relations, age category (adult or juvenile) and sex) and get them in the propoer format for use in Eventnet.

```{r}
setwd("C:\\Users\\Mike\\Documents\\DB_experiments")
lh_df<-read.csv("LH140120.csv",header=T)                      #Read in Life History dataset
lh_df<-lh_df[order(as.numeric(as.POSIXct(lh_df$DATE,format="%d/%m/%Y"))),]

#1. risk-set (Range of times during the experiment during which each individual could have been observed)
risk_df<-read.csv("risk.csv",header=T)
risk_df[,1]<-as.numeric(as.POSIXct(risk_df[,1],format="%Y-%m-%d %H:%M:%S"))
risk_df$WEIGHT<-rep(1,nrow(risk_df))
risk_df<-data.frame(SOURCE=risk_df$source,TARGET=risk_df$target,TIME=risk_df$time,TYPE=risk_df$type,WEIGHT=risk_df$WEIGHT)

#2. Treatment group assignment
group_df<-read.csv("groups.csv",header=T)
group_df[,1]<-as.numeric(as.POSIXct(group_df[,1],format="%Y-%m-%d %H:%M:%S"))
group_df$WEIGHT<-apply(group_df,1,function(x) if(x["type"]=="A"){1} else {0})
group_df$type<-rep("IS_GROUP_A",nrow(group_df))
group_df<-data.frame(SOURCE=group_df$source,TARGET=group_df$target,TIME=group_df$time,TYPE=group_df$type,WEIGHT=group_df$WEIGHT)

#3. Parent-offspring 
m_temp<-lh_df[which(lh_df[,"ID"] %in% group_df$SOURCE),c("ID","MOTHER.ID")]
m_temp<-m_temp[m_temp[,"MOTHER.ID"]!="",]
mfin<-m_temp[!duplicated(m_temp),]  
mrev<-data.frame(ID=mfin[,2],MOTHER.ID=mfin[,1])
mboth<-rbind(mfin,mrev)
mboth<-mboth[!duplicated(mrev),]
m_out<-data.frame(SOURCE=mboth[,1],TARGET=mboth[,2],TIME=group_df[1,"TIME"],TYPE=rep("PARENT-OFFSPRING",nrow(mboth)),WEIGHT=rep(1,nrow(mboth)))
f_temp<-lh_df[which(lh_df[,"ID"] %in% group_df$SOURCE),c("ID","FATHER.ID")]
f_temp<-f_temp[f_temp[,"FATHER.ID"]!="",]
ffin<-f_temp[!duplicated(f_temp),]                  
frev<-data.frame(ID=ffin[,2],FATHER.ID=ffin[,1])
fboth<-rbind(ffin,frev)
fboth<-fboth[!duplicated(frev),]
f_out<-data.frame(SOURCE=fboth[,1],TARGET=fboth[,2],TIME=group_df[1,"TIME"],TYPE=rep("PARENT-OFFSPRING",nrow(fboth)),WEIGHT=rep(1,nrow(fboth)))
all_po<-rbind(m_out,f_out)

#4. Siblings
m_s_temp<-lapply(split(mfin,mfin[,"MOTHER.ID"]),function(x) if(nrow(x)>1) {expand.grid(x[,"ID"],x[,"ID"])} else {NULL})
m_s_df<-do.call(rbind,m_s_temp)
m_s_df<-m_s_df[which(m_s_df[,1]!=m_s_df[,2]),]
f_s_temp<-lapply(split(ffin,ffin[,"FATHER.ID"]),function(x) if(nrow(x)>1) {expand.grid(x[,"ID"],x[,"ID"])} else {NULL})
f_s_df<-do.call(rbind,f_s_temp)
f_s_df<-f_s_df[which(f_s_df[,1]!=f_s_df[,2]),]
all_s_df<-rbind(m_s_df,f_s_df)
all_s_df<-all_s_df[!duplicated(all_s_df),]
all_s_fin<-data.frame(SOURCE=all_s_df[,1],TARGET=all_s_df[,2],TIME=group_df[1,"TIME"],TYPE=rep("SIBLING",nrow(all_s_df)),WEIGHT=rep(1,nrow(all_s_df)))

#5. Breeding partners
p_list<-lapply(split(lh_df,lh_df[,"ID"]),function(x) if(length(which(x[,"PARTNER.ID"]!=""))){data.frame(ID=x[1,"ID"],PARTNER.ID=x[which(x["PARTNER.ID"]!="")[length(which(x["PARTNER.ID"]!=""))],"PARTNER.ID"])} else {NULL})
p_df<-do.call(rbind,p_list)
p_df<-p_df[which(p_df[,1] %in% group_df$SOURCE),]
p_rev<-data.frame(ID=p_df[,2],PARTNER.ID=p_df[,1])
p_both<-rbind(p_df,p_rev)
p_both<-p_both[!duplicated(p_both),]
p_out<-data.frame(SOURCE=p_both[,1],TARGET=p_both[,2],TIME=group_df[1,"TIME"],TYPE=rep("PARTNER",nrow(p_both)),WEIGHT=rep(1,nrow(p_both)))

#6. Age
lh_temp<-lh_df[which(lh_df[,"ID"] %in% group_df$SOURCE),]
ring_dates<-lh_temp[lh_temp[,"CODE"]=="RINGED",c("ID","DATE")]
ring_dates<-ring_dates[!duplicated(ring_dates),]
start_time<-as.numeric(as.POSIXct("19/04/2019",format="%d/%m/%Y"))
is.adult<-as.numeric(as.numeric(as.POSIXct(ring_dates[,"DATE"],format="%d/%m/%Y")) < start_time)
age_df<-data.frame(SOURCE=ring_dates[,"ID"],TARGET=ring_dates[,"ID"],TIME=rep(start_time,nrow(ring_dates)),TYPE=rep("IS_ADULT",nrow(ring_dates)),WEIGHT=is.adult)
age_df<-age_df[age_df[,"WEIGHT"]==1,]

#7. Sex
sex_df<-lh_temp[lh_temp[,"SEX"]!="",c("ID","SEX")]
sex_df<-sex_df[!duplicated(sex_df),]
unk_IDs<-group_df$SOURCE[!group_df$SOURCE %in% sex_df[,1]]
unk_df<-data.frame(SOURCE=unk_IDs,TARGET=unk_IDs,TIME=rep(start_time,length(unk_IDs)),TYPE=rep("SEX",length(unk_IDs)),WEIGHT=rep(0,length(unk_IDs)))
sex_bool<-apply(sex_df,1,function(x) if(toString(x["SEX"])=="F"){1} else if(toString(x["SEX"])=="M"){2})
sex_df2<-data.frame(SOURCE=sex_df[,"ID"],TARGET=sex_df[,"ID"],TIME=rep(start_time,nrow(sex_df)),TYPE=rep("SEX",nrow(sex_df)),WEIGHT=sex_bool)
fin_sex<-rbind(sex_df2,unk_df)
#NEED TO REMOVE the J972 entry with sex as F - mistake in LH sheet.

all_cov<-rbind(group_df,risk_df,fin_sex,age_df,p_out,all_s_fin,all_po)  #Combine the above into a single Eventnet format covariates dataframe
write.csv(all_cov,file="all_cov.csv")
```


Align PRE and POST COOP events with their respective COOP events. 

```{r}
pre_df<-outfin4[outfin4$TYPE %in% c("PRE_COOP"),]             #Filter to get all PRE_COOP events in a single dataframe
pre_df<-pre_df[!is.infinite(as.numeric(pre_df$WEIGHT)),]      #sanity check to ensure that there are no erroneous weights
post_df<-outfin4[outfin4$TYPE %in% c("POST_COOP"),]            #Filter to get all POST_COOP events in a single dataframe
post_df<-post_df[!is.infinite(as.numeric(post_df$WEIGHT)),]     #sanity check to ensure that there are no erroneous weights
cooptemp<-outfin4[outfin4$TYPE %in% c("COOP_SUCCESS","COOP_FAIL"),]                #Filter to get all COOP events in a single dataframe
othertemp<-outfin4[outfin4$TYPE %in% c("SOLO_NO_COOP","REPLACEMENT","SCROUNGE"),]      #Filter to get all other types of event in a single dataframe
chkchk<-which(!pre_df[,"TIME"] %in% pre_df[duplicated(pre_df[,"TIME"]),"TIME"])      #Ensure that if there are any remaining duplicated PRE_COOP events, that they are identified...
pre_df.clip<-pre_df[chkchk,]   #...and filtered out
chkchk2<-which(!post_df[,"TIME"] %in% post_df[duplicated(post_df[,"TIME"]),"TIME"])   #Ensure that if there are any remaining duplicated POST_COOP events, that they are identified...
post_df.clip<-post_df[chkchk2,]      #...and filtered out


#Align PRE-COOP and POST-COOP with respective COOP events (i.e. get additional columns for the dataframe that contain PRE/POST event durations for cooperation events, if such durations can have been calculated reliably)
cooptemp$pre_dur<-unlist(apply(cooptemp,1,function(x) if(length(which((as.numeric(pre_df.clip$TIME) + as.numeric(pre_df.clip$WEIGHT))==as.numeric(x["TIME"])))==1){pre_df.clip[(as.numeric(pre_df.clip$TIME) + as.numeric(pre_df.clip$WEIGHT))==as.numeric(x["TIME"]),"WEIGHT"]} else {NA}))               #For each cooperation event, determine whether there is a PRE_COOP event that ends as the onset of the cooperation event begins. If so, return the duration of the PRE_COOP event, otherwise return NA. Results in an additional column indicating PRE_COOP event duration (if calculable) for each cooperation event.

cooptemp$post_dur<-unlist(apply(cooptemp,1,function(x) if(length(which(as.numeric(post_df.clip$TIME)==(as.numeric(x["TIME"]) + as.numeric(x["WEIGHT"]))))==1){post_df.clip[as.numeric(post_df.clip$TIME)==(as.numeric(x["TIME"]) + as.numeric(x["WEIGHT"])),"WEIGHT"]} else {NA}))            #For each cooperation event, determine whether there is a POST_COOP event that begins as the cooperation event ends. If so, return the duration of the POST_COOP event, otherwise return NA. Results in an additional column indicating POST_COOP event duration (if calculable) for each cooperation event.

othertemp<-cbind(othertemp,pre_dur=rep(NA,nrow(othertemp)),post_dur=rep(NA,nrow(othertemp)))   #PRE and POST events are not relevant for non-cooperation events, so NA values for these.
outfin5<-rbind(cooptemp,othertemp)                   #Re-Combine dataframes of cooperation and non-cooperation events       
outfin5<-outfin5[order(as.numeric(outfin5$TIME)),]    #Ensure the events in the dataframe are ordered by time since beginning of the experiment.
```


Remove individuals that don't have a treatment group assignment, also remove those that might have had the wrong class label (37 events) due to RFID code duplication or input error, and then output the final REM dataset in Eventnet format

```{r}
outfin6<-outfin5[outfin5$SOURCE %in% group_df$SOURCE,]    #final filtering to ensure that all individuals in the final dataframe have a treatment group assigned.
outfin7<-outfin6[outfin6$TARGET %in% group_df$TARGET,]    #final filtering to ensure that all individuals in the final dataframe have a treatment group assigned.

coop_temp<-outfin7[outfin7$TYPE %in% c("COOP_SUCCESS","COOP_FAIL"),]    #Get a dataframe of just the cooperation events
coop_temp$temp_source.isgroupA<-apply(coop_temp,1,function(x) group_df[match(x["SOURCE"],group_df$SOURCE),"WEIGHT"])   #Get a vector of the group assignments of the SOURCE for each cooperation event (1=group A, 0=group B)
coop_temp$temp_target.isgroupA<-apply(coop_temp,1,function(x) group_df[match(x["TARGET"],group_df$TARGET),"WEIGHT"])   #Get a vector of the group assignments of the TARGET for each cooperation event (1=group A, 0=group B)
coop_temp$same_group<-apply(coop_temp,1,function(x)     if(x["temp_source.isgroupA"]==x["temp_target.isgroupA"]){1} else{0})
eventcheck<-apply(coop_temp,1,function(x) if(x["TYPE"]=="COOP_FAIL" && x["same_group"]==0){"CORRECT"} else if(x["TYPE"]=="COOP_FAIL" && x["same_group"]==1){"WRONG"} else if(x["TYPE"]=="COOP_SUCCESS" && x["same_group"]==1){"CORRECT"} else if(x["TYPE"]=="COOP_SUCCESS" && x["same_group"]==0){"WRONG"} else {"NOT_RELEVANT"})     #Get an indicator of whether two members of a dyad belong to the same treatment group (1) or not (0)
correct_coop<-coop_temp[which(eventcheck=="CORRECT"),c("SOURCE","TARGET","TIME","TYPE","WEIGHT","SITE","lock_bool","high_bool","low_bool","ANTENNA","pre_dur","post_dur")]
outtemp<-outfin7[outfin7$TYPE %in% c("SOLO_NO_COOP","PRE_COOP","POST_COOP","REPLACEMENT","SCROUNGE"),]
outfin8<-rbind(correct_coop,outtemp)
outfin8<-droplevels(outfin8)
outfin8<-outfin8[order(as.numeric(outfin8$TIME)),]    #Ensure the events in the dataframe are ordered by time since beginning of the experiment.
write.csv(outfin8,"outfin8.csv")
```


Test the effect of concatenation on the proportion of cooperation events that are successful and the proportion of total time spent cooperating that consisted of time spent successfully cooperating.

```{r}
#Number of events
mcnemar.test(matrix(c(4265,3058,1727,1390),nrow=2,dimnames=list("No.CAT"=c("Success","Failure"),"15.CAT"=c("Success","Failure"))))

#Duration of events (in seconds)
mcnemar.test(matrix(c(11349,10501,16338,12407),nrow=2,dimnames=list("No.CAT"=c("Success","Failure"),"15.CAT"=c("Success","Failure"))))
```










